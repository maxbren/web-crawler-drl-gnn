{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict, deque, defaultdict\n",
    "from nervenet import NerveNet_GNN\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: when you see a loss of nan in the prints its okay, if the num of steps is less than the freq of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/clone-and-detach-in-v0-4-0/16861/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of things todo\n",
    "- ~~Add Double DQN and make sure vanilla DQN formula is correct~~\n",
    "- ~~Need to track the grads and detach the grads for outputs that arent a part of the actual minibatch fit~~\n",
    "- ~~Debug multiple props~~\n",
    "- ~~Track the grad for multiple props~~\n",
    "- ~~Go through \"https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\"~~\n",
    "- ~~After going through ^ see if i need to change my loss because i think that I need to reshape or something so that the vector is summed and then meaned which means that the mean does nothing since there is only one sample per train anyway~~\n",
    "- ~~Also make sure to add huber loss~~\n",
    "- ~~Add dikstras to get optimal path from init to goal and use this both as reward and to limit the the path length in an ep~~\n",
    "- check if adding cuda actually made it slower\n",
    "- ~~Getting a loss of nan sometimes after running it for a while, see whats up~~\n",
    "- setup a framework/csv to keep track of all hyperparams when im tuning, even remember things that arent constants such as what feats i use for a node etc.\n",
    "    - Might also want to add time data for certain parts of the code\n",
    "- Try adding the link encodings to each node feature cuz right now i just use title\n",
    "- Do some tuning to get good results\n",
    "- Try adding priotirzied exp replay or at least weights based on if its a terminal tuple\n",
    "- Try instead of looping through for each prop, expliclty unrolling each prop to make sure that replacing the var node states isnt an issue\n",
    "- See if i need node feats and goal feats to have grad\n",
    "- Add in ignore intenral nodes and see if that improves performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab data and make Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page:\n",
    "    def __init__(self, text, links):\n",
    "        self.text = text\n",
    "        self.links = links  # out-links\n",
    "        self.in_links = []\n",
    "        self.indx = None  # Relative to the ordered dict below\n",
    "        self.feats = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wiki-dict i want\n",
    "with open('data/animals-D3-small-30K-nodes40-edges202-max10-minout2-minin3_w_features.pkl', 'rb') as f:\n",
    "    pages = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ordered dict so i can use indices to refer to pages\n",
    "# Convert pages to ordered dict\n",
    "pages = OrderedDict(pages)\n",
    "# Add indices and get feats for each page\n",
    "node_feats = []\n",
    "for indx, (title, obj) in enumerate(pages.items()):\n",
    "    obj.indx = indx\n",
    "    node_feats.append(obj.feats)\n",
    "node_feats = np.stack(node_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make edges for graph generation\n",
    "edges = []\n",
    "for title, obj in pages.items():\n",
    "    for link in obj.links:\n",
    "        in_node = obj.indx\n",
    "        out_node = pages[link].indx\n",
    "        edges.append((in_node, out_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make whole graph\n",
    "G_whole = nx.DiGraph()\n",
    "G_whole.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_kamada_kawai(G_whole, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode Constants\n",
    "num_eps = 1000\n",
    "max_ep_steps = 10\n",
    "ignore_internal_nodes = False\n",
    "num_props = 1  # number of propogations per step\n",
    "# optimal num of actions of an ep is the shortest path from init to goal minus one\n",
    "shortest_path_range_allowed = [4, 6]  # in number of edges between init node and goal node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data/Model Constants\n",
    "num_nodes = len(pages)\n",
    "num_edges = len(edges)  # Only needed for deepmind\n",
    "node_feat_size = node_feats.shape[1]\n",
    "edge_feat_size = ...  # Only needed for deepmind\n",
    "node_hidden_size = 32  \n",
    "edge_hidden_size = ...  # Only needed for deepmind\n",
    "message_size = 32  # Only for nervenet\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal Constants\n",
    "# there are three ways im testing, \n",
    "# 1)if i put it in the state update func\n",
    "# 2) if I send it in to the output i.e. after the update \n",
    "goal_opt = 2\n",
    "# Another option is whether to put the goal through the input layer or not\n",
    "goal_input_layer = True\n",
    "if goal_input_layer:\n",
    "    goal_size = node_hidden_size\n",
    "else:\n",
    "    goal_size = node_feat_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Constans\n",
    "num_warmup_steps = 2000\n",
    "mem_max_size = 100000\n",
    "init_eps = 1.0\n",
    "final_eps = 0.05\n",
    "final_exp_step = 5000\n",
    "target_update_freq = 50  # in overall steps\n",
    "train_freq = 4  # in overall steps\n",
    "double_dqn = True\n",
    "minibatch_size = 32\n",
    "gamma = 0.99\n",
    "learning_rate = 1e-3\n",
    "clip_grads = True\n",
    "grad_clamp_val = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = []\n",
    "# for _ in range(200):\n",
    "#     init_node = random.randint(0, num_nodes-1)\n",
    "#     goal_node = random.randint(0, num_nodes-1)\n",
    "#     if not nx.has_path(G_whole, init_node, goal_node) or init_node == goal_node:\n",
    "#         continue\n",
    "#     shortest_path_length = nx.shortest_path_length(G_whole, init_node, goal_node)\n",
    "#     if shortest_path_length == 1:\n",
    "#         continue\n",
    "#     arr.append(shortest_path_length)\n",
    "# np.array(arr).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    return cosine_similarity(a, b)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now this is -1 per timestep +5 on terminal for reaching goal, -5 on terminal for not reaching goal\n",
    "# And when it reaches the goal, give add (shortest_path_length - 1) - num actions taken (neg number)\n",
    "def reward_func(terminal, reach_goal, shortest_path_length, num_actions_taken):\n",
    "    rew = -1\n",
    "    if terminal:\n",
    "        if reach_goal:\n",
    "            assert num_actions_taken >= (shortest_path_length-1)\n",
    "            rew += 10\n",
    "            rew += ((shortest_path_length-1) - num_actions_taken)  # optimal num actions - num actions taken\n",
    "        else:\n",
    "            rew += -5\n",
    "    return rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.memory  = deque(maxlen=mem_max_size)\n",
    "        self.eps = init_eps\n",
    "        # Make behavior gnn and target gnn\n",
    "        self.gnn = NerveNet_GNN(node_feat_size, node_hidden_size, message_size, output_size, goal_size, goal_opt, device).to(device)\n",
    "        self.gnn_ = NerveNet_GNN(node_feat_size, node_hidden_size, message_size, output_size, goal_size, goal_opt, device).to(device)\n",
    "        self.update_target_models()\n",
    "        self.optimizer = optim.Adam(self.gnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    # train_step is overall train step (not just per ep)\n",
    "    def update_implicit_policy(self, train_step):\n",
    "        if train_step <= final_exp_step:\n",
    "            self.eps = final_eps + (init_eps - final_eps) * np.maximum(0, (final_exp_step - train_step)) / final_exp_step\n",
    "    \n",
    "    def remember(self, mem_tuple):\n",
    "        self.memory.append(mem_tuple)\n",
    "#         mem = self.memory[-1]\n",
    "#         state, action, reward, next_state, done = mem[0], mem[1], mem[2], mem[3], mem[4]\n",
    "#         print('State::')\n",
    "#         print('num nodes: {}  goal_feats: {}  G_curr nodes: {}  current nodes: {}'.format(state['num_nodes'], state['goal_feats'], state['G_curr'].nodes, state['current_nodes']))\n",
    "\n",
    "#         print('Action::'+str(action))\n",
    "\n",
    "#         print('Reward::'+str(reward))\n",
    "\n",
    "#         print('Next State::')\n",
    "#         print('num nodes: {}  goal_feats: {}  G_curr nodes: {}  current nodes: {}'.format(next_state['num_nodes'], next_state['goal_feats'], next_state['G_curr'].nodes, next_state['current_nodes']))\n",
    "\n",
    "        \n",
    "    # act (eps-greedy)\n",
    "    def select_node(self, outputs, warmup=False):\n",
    "        # Explore\n",
    "        if random.random() < self.eps or warmup:\n",
    "            action = random.randint(0, outputs.shape[0]-1)\n",
    "        else:\n",
    "            action = outputs.argmax()\n",
    "        return action\n",
    "    \n",
    "    # TODO: See if soft-update improves performance\n",
    "    def update_target_models(self):\n",
    "        self.gnn_.load_state_dict(self.gnn.state_dict())\n",
    "#         self.gnn_ = deepcopy(self.gnn)\n",
    "#         self.gnn_.input_model = deepcopy(self.gnn.input_model)\n",
    "#         self.gnn_.message_model = deepcopy(self.gnn.message_model)\n",
    "#         self.gnn_.update_model = deepcopy(self.gnn.update_model)\n",
    "#         self.gnn_.output_model = deepcopy(self.gnn.output_model)\n",
    "    \n",
    "    # DEBUG -----------\n",
    "    def print_memory(self):\n",
    "        for mem in self.memory:\n",
    "            state, action, reward, next_state, done = mem[0], mem[1], mem[2], mem[3], mem[4]\n",
    "            print('State::')\n",
    "            print('num nodes: {}  goal_feats: {}  G_curr nodes: {}  current nodes: {}'.format(state['num_nodes'], state['goal_feats'], state['G_curr'].nodes, state['current_nodes']))\n",
    "            \n",
    "            print('Action::'+str(action))\n",
    "            \n",
    "            print('Reward::'+str(reward))\n",
    "            \n",
    "            print('Next State::')\n",
    "            print('num nodes: {}  goal_feats: {}  G_curr nodes: {}  current nodes: {}'.format(next_state['num_nodes'], next_state['goal_feats'], next_state['G_curr'].nodes, next_state['current_nodes']))\n",
    "            \n",
    "    # ------------------\n",
    "    \n",
    "    # TODO: Figure out how to optimize this and _fit to run multiple graphs/states at once\n",
    "    def train(self):\n",
    "        # Sample a minibatch of memory tuples\n",
    "        minibatch = random.sample(self.memory, minibatch_size)\n",
    "        output_vals, expected_vals = [], []\n",
    "        \n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            with torch.no_grad():\n",
    "                target = reward\n",
    "                if not done:\n",
    "                    if not double_dqn:\n",
    "                        outputs = propogate(self.gnn_, next_state).detach().cpu().numpy()  # Detach grad\n",
    "                        target = reward + gamma * outputs.max()\n",
    "                    else:\n",
    "                        outputs_beh = propogate(self.gnn, next_state).detach().cpu().numpy()\n",
    "                        next_state_action = np.argmax(outputs_beh)\n",
    "                        outputs_tar = propogate(self.gnn_, next_state).detach().cpu().numpy()\n",
    "                        outputs_tar_action_val = outputs_tar[next_state_action]\n",
    "                        target = reward + gamma * outputs_tar_action_val\n",
    "            \n",
    "            # Run state through behavior model (NEEDS GRAD)\n",
    "            state_action_output = propogate(self.gnn, state)\n",
    "            state_action_output_val = state_action_output[action]\n",
    "            output_vals.append(state_action_output_val)\n",
    "            \n",
    "            # Add Target\n",
    "            expected_vals.append(target)\n",
    "            \n",
    "        # Stack \n",
    "        output_stack = torch.stack(output_vals).unsqueeze(1)\n",
    "        expected_stack = np.stack(expected_vals).reshape(-1, 1)\n",
    "        expected_stack = torch.tensor(expected_stack, dtype=torch.float, device=device)\n",
    "        assert output_stack.shape == (minibatch_size, 1), output_stack.shape\n",
    "        assert output_stack.shape == expected_stack.shape, expected_stack.shape\n",
    "        assert output_stack.requires_grad == True\n",
    "        assert expected_stack.requires_grad == False\n",
    "        \n",
    "        # Backprop\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.gnn.backward(output_stack, expected_stack)\n",
    "        if clip_grads:\n",
    "            for param in self.gnn.parameters():\n",
    "                param.grad.data.clamp_(-grad_clamp_val, grad_clamp_val)\n",
    "        self.optimizer.step()\n",
    "#         print('loss: {}'.format(loss))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_indx is the same indx as G_curr and G_whole\n",
    "def add_children(G_curr, node_indx, goal_node_indx, current_nodes):\n",
    "    achieved_goal = False\n",
    "    # Check the children of the node to see if they need to be added to the current graph\n",
    "    children = G_whole.successors(node_indx)\n",
    "    for child in children:\n",
    "        # Add child if not in G and check if goal\n",
    "        if child not in G_curr:\n",
    "            G_curr.add_node(child)\n",
    "            current_nodes.update({child: len(current_nodes)})\n",
    "            if child == goal_node_indx:\n",
    "                achieved_goal = True\n",
    "        # If the edge doesnt exist add it\n",
    "        if not G_curr.has_edge(node_indx, child):\n",
    "            G_curr.add_edge(node_indx, child)\n",
    "    assert sorted(list(current_nodes.values())) == list(current_nodes.values())\n",
    "    return achieved_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_ep():\n",
    "    current_try = 0\n",
    "    while True:\n",
    "        current_try += 1\n",
    "#         if current_try >= 50:\n",
    "#              print('Current try for initialize ep is at: {}'.format(current_try))\n",
    "        init_node = random.randint(0, num_nodes-1)\n",
    "        goal_node = random.randint(0, num_nodes-1)\n",
    "        # restart if goal node is init node, or no path\n",
    "        if init_node == goal_node or not nx.has_path(G_whole, init_node, goal_node):\n",
    "            continue\n",
    "        # restart if shortest path is too long or too short\n",
    "        shortest_path = nx.shortest_path_length(G_whole, init_node, goal_node)\n",
    "        if shortest_path < shortest_path_range_allowed[0] or shortest_path > shortest_path_range_allowed[1]:\n",
    "            continue\n",
    "        break\n",
    "        \n",
    "    # Get goal feats\n",
    "    goal_feats = node_feats[goal_node]\n",
    "    assert goal_feats.shape == (node_feat_size,)\n",
    "    # Make init graph\n",
    "    G_init = nx.DiGraph()\n",
    "    G_init.add_node(init_node)\n",
    "    current_nodes = OrderedDict({init_node: 0})  # Init current nodes dict\n",
    "    got_goal = add_children(G_init, init_node, goal_node, current_nodes)\n",
    "#     print(current_nodes.values())\n",
    "#     print(sorted(list(current_nodes.values())))\n",
    "    assert sorted(list(current_nodes.values())) == list(current_nodes.values())\n",
    "    assert not got_goal\n",
    "    \n",
    "    return G_init, current_nodes, goal_node, goal_feats, shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_nodes: ordereddict with keys as abs node indices, values as rel node indices (rel to the ordered dict)\n",
    "def get_predecessors(G_curr, current_nodes):\n",
    "    all_preds = []  # List of lists\n",
    "    for node in current_nodes.keys():\n",
    "        preds_abs = G_curr.predecessors(node)  # abs to all nodes, keys to the dict\n",
    "        preds_rel = [current_nodes[x] for x in preds_abs]\n",
    "        all_preds.append(preds_rel)\n",
    "    return all_preds  # Returns a list of lists with the values being tth rel node indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propogate(gnn, state):\n",
    "    num_nodes, goal_feats, G_curr, current_nodes = state['num_nodes'], state['goal_feats'], state['G_curr'], state['current_nodes']\n",
    "    node_feats_tensor = torch.tensor(node_feats, device=device, requires_grad=True, dtype=torch.float)\n",
    "    goal_feats_tensor = torch.tensor(goal_feats, device=device, requires_grad=True, dtype=torch.float)\n",
    "    # Grab the feats of the nodes in the current graph\n",
    "    node_states = node_feats_tensor[list(current_nodes.keys())] \n",
    "    # If goal_input_layer is True then embed the goal by sending it into the input layer\n",
    "    if goal_input_layer:\n",
    "        goal_embeddings = gnn.input_model(goal_feats_tensor.reshape(1, -1)).flatten()\n",
    "        stacked_goal_embeds = torch.stack([goal_embeddings] * num_nodes)\n",
    "    else:\n",
    "        stacked_goal_embeds = torch.stack([goal_feats_tensor] * num_nodes)\n",
    "    for p in range(num_props):\n",
    "        predecessors = get_predecessors(G_curr, current_nodes)\n",
    "        node_states, outputs = gnn(node_states, p == 0, p == num_props-1, predecessors, stacked_goal_embeds)\n",
    "        assert node_states.shape == (num_nodes, node_hidden_size)\n",
    "    assert outputs.flatten().shape == (num_nodes,)\n",
    "    return outputs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep copy everything before it goes into a state\n",
    "def make_state(current_nodes, goal_feats, G_curr):\n",
    "    current_nodes_copy = current_nodes.copy()\n",
    "    goal_feats_copy = goal_feats\n",
    "    G_curr_copy = G_curr.copy()\n",
    "    return {'num_nodes': len(current_nodes_copy), 'goal_feats': goal_feats_copy, 'G_curr': G_curr_copy, 'current_nodes': current_nodes_copy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to fill memory of agent, no training\n",
    "def warmup_episode(total_step):\n",
    "    G_curr, current_nodes, goal_node, goal_feats, shortest_path_length = initialize_ep()\n",
    "    assert len(current_nodes) > 1\n",
    "    ep_rew = 0\n",
    "    state = make_state(current_nodes, goal_feats, G_curr)\n",
    "    for step in range(max_ep_steps):\n",
    "        with torch.no_grad():\n",
    "            outputs = propogate(agent.gnn, state).detach().cpu().numpy()\n",
    "        selected_node_rel = agent.select_node(outputs, warmup=True)\n",
    "        selected_node_abs = list(current_nodes.keys())[selected_node_rel]\n",
    "        \n",
    "        state = deepcopy(state)\n",
    "        \n",
    "        achieved_goal = add_children(G_curr, selected_node_abs, goal_node, current_nodes)\n",
    "        done = True if (step == max_ep_steps - 1) or achieved_goal or total_step == num_warmup_steps else False\n",
    "        rew = reward_func(done, achieved_goal, shortest_path_length, step+1)\n",
    "        ep_rew += rew\n",
    "        \n",
    "        next_state = make_state(current_nodes, goal_feats, G_curr)\n",
    "        memory_tuple = (state, selected_node_rel, rew, next_state, done)\n",
    "        agent.remember(memory_tuple)\n",
    "        \n",
    "        state = deepcopy(next_state)\n",
    "        \n",
    "        total_step += 1\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "#     print('Episode {}  Mem. size: {}  Reward: {}  Achieved goal: {}  Optimal num steps: {}  Taken num steps: {}'.format(ep+1, len(agent.memory), ep_rew, achieved_goal, shortest_path_length-1,step+1))\n",
    "    \n",
    "    return total_step, ep_rew, achieved_goal, shortest_path_length-1, step+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(ep, total_step):\n",
    "    # Init. the episode graph and current nodes\n",
    "    G_curr, current_nodes, goal_node, goal_feats, shortest_path_length = initialize_ep()\n",
    "    assert len(current_nodes) > 1\n",
    "    ep_rew = 0\n",
    "    ep_losses = []\n",
    "    ep_history = [G_curr.copy()]  # Save the graphs\n",
    "    state = make_state(current_nodes, goal_feats, G_curr)\n",
    "    for step in range(max_ep_steps):\n",
    "#         print ('------------')\n",
    "        \n",
    "        # Pick node to explore by propogating -- Take Action --\n",
    "        with torch.no_grad():\n",
    "            outputs = propogate(agent.gnn, state).detach().cpu().numpy()\n",
    "        selected_node_rel = agent.select_node(outputs)\n",
    "        selected_node_abs = list(current_nodes.keys())[selected_node_rel]\n",
    "        \n",
    "        # Debug ---\n",
    "#         print('STATE PRE COPY')\n",
    "#         print('num nodes: {}  goal_feats: {}  G_curr nodes: {}  current nodes: {}'.format(state['num_nodes'], state['goal_feats'], state['G_curr'].nodes, state['current_nodes']))\n",
    "#         print('\\n')\n",
    "        # ---------\n",
    "        \n",
    "        # TODO: Check that this actually deep copies eveythign so that the graph/current nodes in state dont change below\n",
    "        state = deepcopy(state)\n",
    "\n",
    "        # Add the children -- Run env forward a step --\n",
    "        achieved_goal = add_children(G_curr, selected_node_abs, goal_node, current_nodes)\n",
    "        ep_history.append(G_curr.copy())\n",
    "        # Done if goal found or end of ep\n",
    "        done = True if (step == max_ep_steps - 1) or achieved_goal else False\n",
    "        rew = reward_func(done, achieved_goal, shortest_path_length, step+1)\n",
    "        ep_rew += rew\n",
    "\n",
    "        # Add to agent memory pool\n",
    "        next_state = make_state(current_nodes, goal_feats, G_curr)\n",
    "        \n",
    "        memory_tuple = (state, selected_node_rel, rew, next_state, done)\n",
    "        agent.remember(memory_tuple)\n",
    "        \n",
    "         # Debug ---\n",
    "#         print('STATE After COPY')\n",
    "#         print('num nodes: {}  goal_feats: {}  G_curr nodes: {}  current nodes: {}'.format(state['num_nodes'], state['goal_feats'], state['G_curr'].nodes, state['current_nodes']))\n",
    "#         print('\\n')\n",
    "        # ---------\n",
    "        \n",
    "        state = deepcopy(next_state)\n",
    "        \n",
    "        # Debug ---\n",
    "#         print('NEXT STATE')\n",
    "#         print('num nodes: {}  goal_feats: {}  G_curr nodes: {}  current nodes: {}'.format(next_state['num_nodes'], next_state['goal_feats'], next_state['G_curr'].nodes, next_state['current_nodes']))\n",
    "#         print('\\n')\n",
    "        # ---------\n",
    "        \n",
    "        # Update eps-greedy policy\n",
    "        agent.update_implicit_policy(total_step)\n",
    "        \n",
    "        # Update target model if necc\n",
    "        if total_step % target_update_freq == 0 and total_step != 0:\n",
    "            agent.update_target_models()\n",
    "            \n",
    "        # Train if necc\n",
    "        if total_step % train_freq == 0 and total_step != 0 and len(agent.memory) >= minibatch_size:\n",
    "#             print('step: {}'.format(total_step))\n",
    "#             print('mem: {}'.format(len(agent.memory)))\n",
    "            mb_loss = agent.train()\n",
    "            ep_losses.append(mb_loss)\n",
    "        \n",
    "        total_step += 1\n",
    "        if done:\n",
    "            break\n",
    "#     agent.print_memory()\n",
    "    \n",
    "    print('Episode {}  Epsilon: {:2f}  Mem. size: {}  Avg loss: {:3f}  Reward: {}  Achieved goal: {}  Optimal num steps: {}  Taken num steps: {}'.format(ep+1, agent.eps, len(agent.memory), np.array(ep_losses).mean(), ep_rew, achieved_goal, shortest_path_length-1,step+1))\n",
    "    \n",
    "    return total_step, ep_history, np.array(ep_losses).mean(), ep_rew\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Warmup initiated ----------\n",
      "\n",
      "Warmup stage summary:  Memory size: 2001  Avg ep rew: -13.32  Achieved goal ratio: 0.14  Avg opt num steps: 3.46  Avg num steps taken: 9.71\n",
      "\n",
      "---------- Training initiated ----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mbrenner/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py:3215: MatplotlibDeprecationWarning: \n",
      "The `xmin` argument was deprecated in Matplotlib 3.0 and will be removed in 3.2. Use `left` instead.\n",
      "  alternative='`left`', obj_type='argument')\n",
      "/Users/mbrenner/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py:3221: MatplotlibDeprecationWarning: \n",
      "The `xmax` argument was deprecated in Matplotlib 3.0 and will be removed in 3.2. Use `right` instead.\n",
      "  alternative='`right`', obj_type='argument')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1  Epsilon: 0.998290  Mem. size: 2011  Avg loss: 1.038605  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 2  Epsilon: 0.996390  Mem. size: 2021  Avg loss: 0.749148  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 3  Epsilon: 0.994490  Mem. size: 2031  Avg loss: 0.891767  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 4  Epsilon: 0.992970  Mem. size: 2039  Avg loss: 0.905710  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 5  Epsilon: 0.991070  Mem. size: 2049  Avg loss: 0.620521  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 6  Epsilon: 0.989170  Mem. size: 2059  Avg loss: 0.900384  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 7  Epsilon: 0.987270  Mem. size: 2069  Avg loss: 0.696560  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 8  Epsilon: 0.985370  Mem. size: 2079  Avg loss: 0.977791  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 9  Epsilon: 0.983470  Mem. size: 2089  Avg loss: 0.721711  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 10  Epsilon: 0.981570  Mem. size: 2099  Avg loss: 1.005336  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 11  Epsilon: 0.979670  Mem. size: 2109  Avg loss: 1.041966  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 12  Epsilon: 0.977770  Mem. size: 2119  Avg loss: 0.750914  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 13  Epsilon: 0.975870  Mem. size: 2129  Avg loss: 0.892232  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 14  Epsilon: 0.973970  Mem. size: 2139  Avg loss: 0.662493  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 15  Epsilon: 0.972070  Mem. size: 2149  Avg loss: 0.526496  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 16  Epsilon: 0.970170  Mem. size: 2159  Avg loss: 0.779322  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 17  Epsilon: 0.968270  Mem. size: 2169  Avg loss: 1.060987  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 18  Epsilon: 0.966370  Mem. size: 2179  Avg loss: 0.739698  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 19  Epsilon: 0.964470  Mem. size: 2189  Avg loss: 0.622755  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 20  Epsilon: 0.962570  Mem. size: 2199  Avg loss: 0.657465  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 21  Epsilon: 0.960860  Mem. size: 2208  Avg loss: 0.757948  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 22  Epsilon: 0.958960  Mem. size: 2218  Avg loss: 0.997878  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 23  Epsilon: 0.957630  Mem. size: 2225  Avg loss: 0.978579  Reward: 0  Achieved goal: True  Optimal num steps: 4  Taken num steps: 7\n",
      "Episode 24  Epsilon: 0.955730  Mem. size: 2235  Avg loss: 0.912125  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 25  Epsilon: 0.953830  Mem. size: 2245  Avg loss: 0.771833  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 26  Epsilon: 0.952120  Mem. size: 2254  Avg loss: 0.929459  Reward: -4  Achieved goal: True  Optimal num steps: 4  Taken num steps: 9\n",
      "Episode 27  Epsilon: 0.950220  Mem. size: 2264  Avg loss: 0.824528  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 28  Epsilon: 0.948320  Mem. size: 2274  Avg loss: 0.836369  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 29  Epsilon: 0.946420  Mem. size: 2284  Avg loss: 0.666884  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 30  Epsilon: 0.944520  Mem. size: 2294  Avg loss: 0.777120  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 31  Epsilon: 0.942620  Mem. size: 2304  Avg loss: 0.845151  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 32  Epsilon: 0.940720  Mem. size: 2314  Avg loss: 1.020594  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 33  Epsilon: 0.939010  Mem. size: 2323  Avg loss: 1.324961  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 34  Epsilon: 0.937110  Mem. size: 2333  Avg loss: 0.859456  Reward: -6  Achieved goal: True  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 35  Epsilon: 0.935210  Mem. size: 2343  Avg loss: 1.022130  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 36  Epsilon: 0.933310  Mem. size: 2353  Avg loss: 1.083791  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 37  Epsilon: 0.931410  Mem. size: 2363  Avg loss: 1.553135  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 38  Epsilon: 0.929510  Mem. size: 2373  Avg loss: 0.945482  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 39  Epsilon: 0.928180  Mem. size: 2380  Avg loss: 1.321999  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 40  Epsilon: 0.927040  Mem. size: 2386  Avg loss: 1.112186  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 41  Epsilon: 0.925140  Mem. size: 2396  Avg loss: 1.138938  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 42  Epsilon: 0.923240  Mem. size: 2406  Avg loss: 1.237539  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 43  Epsilon: 0.922100  Mem. size: 2412  Avg loss: 1.295514  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 44  Epsilon: 0.920200  Mem. size: 2422  Avg loss: 1.319507  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 45  Epsilon: 0.918300  Mem. size: 2432  Avg loss: 1.657988  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 46  Epsilon: 0.916970  Mem. size: 2439  Avg loss: 0.965342  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 47  Epsilon: 0.915070  Mem. size: 2449  Avg loss: 1.449646  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 48  Epsilon: 0.913170  Mem. size: 2459  Avg loss: 1.174761  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 49  Epsilon: 0.911270  Mem. size: 2469  Avg loss: 1.479616  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 50  Epsilon: 0.909370  Mem. size: 2479  Avg loss: 1.189784  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 51  Epsilon: 0.907470  Mem. size: 2489  Avg loss: 1.243585  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 52  Epsilon: 0.905570  Mem. size: 2499  Avg loss: 1.190495  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 53  Epsilon: 0.903670  Mem. size: 2509  Avg loss: 1.377821  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 54  Epsilon: 0.901770  Mem. size: 2519  Avg loss: 1.509226  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 55  Epsilon: 0.899870  Mem. size: 2529  Avg loss: 1.427207  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 56  Epsilon: 0.897970  Mem. size: 2539  Avg loss: 1.231372  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 57  Epsilon: 0.896070  Mem. size: 2549  Avg loss: 1.175482  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 58  Epsilon: 0.894170  Mem. size: 2559  Avg loss: 1.540908  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 59  Epsilon: 0.892270  Mem. size: 2569  Avg loss: 1.411586  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 60  Epsilon: 0.890370  Mem. size: 2579  Avg loss: 1.589625  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 61  Epsilon: 0.888470  Mem. size: 2589  Avg loss: 1.031377  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 62  Epsilon: 0.886570  Mem. size: 2599  Avg loss: 1.478754  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 63  Epsilon: 0.885620  Mem. size: 2604  Avg loss: 1.864934  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 64  Epsilon: 0.883720  Mem. size: 2614  Avg loss: 1.738052  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 65  Epsilon: 0.881820  Mem. size: 2624  Avg loss: 1.298871  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 66  Epsilon: 0.879920  Mem. size: 2634  Avg loss: 1.464714  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 67  Epsilon: 0.878020  Mem. size: 2644  Avg loss: 1.431596  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 68  Epsilon: 0.876120  Mem. size: 2654  Avg loss: 1.549039  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 69  Epsilon: 0.874220  Mem. size: 2664  Avg loss: 1.923736  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 70  Epsilon: 0.872320  Mem. size: 2674  Avg loss: 1.252952  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 71  Epsilon: 0.870420  Mem. size: 2684  Avg loss: 1.709274  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 72  Epsilon: 0.868520  Mem. size: 2694  Avg loss: 2.059641  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 73  Epsilon: 0.867000  Mem. size: 2702  Avg loss: 1.596411  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 74  Epsilon: 0.865100  Mem. size: 2712  Avg loss: 1.419939  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 75  Epsilon: 0.863580  Mem. size: 2720  Avg loss: 1.671925  Reward: -2  Achieved goal: True  Optimal num steps: 4  Taken num steps: 8\n",
      "Episode 76  Epsilon: 0.861680  Mem. size: 2730  Avg loss: 1.647891  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 77  Epsilon: 0.859780  Mem. size: 2740  Avg loss: 1.596918  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 78  Epsilon: 0.858260  Mem. size: 2748  Avg loss: 1.600335  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 79  Epsilon: 0.856360  Mem. size: 2758  Avg loss: 1.817229  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 80  Epsilon: 0.854460  Mem. size: 2768  Avg loss: 1.788460  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 81  Epsilon: 0.853130  Mem. size: 2775  Avg loss: 1.500298  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 82  Epsilon: 0.851230  Mem. size: 2785  Avg loss: 1.525622  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 83  Epsilon: 0.849330  Mem. size: 2795  Avg loss: 1.709787  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 84  Epsilon: 0.847430  Mem. size: 2805  Avg loss: 1.526709  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 85  Epsilon: 0.846670  Mem. size: 2809  Avg loss: 2.328534  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 86  Epsilon: 0.845150  Mem. size: 2817  Avg loss: 1.566073  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 87  Epsilon: 0.843250  Mem. size: 2827  Avg loss: 2.105646  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 88  Epsilon: 0.841350  Mem. size: 2837  Avg loss: 1.762640  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 89  Epsilon: 0.839450  Mem. size: 2847  Avg loss: 1.911796  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 90  Epsilon: 0.837930  Mem. size: 2855  Avg loss: 1.613791  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 91  Epsilon: 0.836220  Mem. size: 2864  Avg loss: 2.546763  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 92  Epsilon: 0.834320  Mem. size: 2874  Avg loss: 1.610373  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 93  Epsilon: 0.832420  Mem. size: 2884  Avg loss: 2.183232  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 94  Epsilon: 0.830520  Mem. size: 2894  Avg loss: 2.181719  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 95  Epsilon: 0.828620  Mem. size: 2904  Avg loss: 1.663959  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 96  Epsilon: 0.826720  Mem. size: 2914  Avg loss: 2.012360  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 97  Epsilon: 0.824820  Mem. size: 2924  Avg loss: 1.880388  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 98  Epsilon: 0.822920  Mem. size: 2934  Avg loss: 1.748087  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 99  Epsilon: 0.821020  Mem. size: 2944  Avg loss: 1.925825  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 100  Epsilon: 0.819120  Mem. size: 2954  Avg loss: 1.801766  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 101  Epsilon: 0.817220  Mem. size: 2964  Avg loss: 1.769511  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 102  Epsilon: 0.815320  Mem. size: 2974  Avg loss: 1.876079  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 103  Epsilon: 0.813420  Mem. size: 2984  Avg loss: 2.355082  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 104  Epsilon: 0.811520  Mem. size: 2994  Avg loss: 2.265794  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 105  Epsilon: 0.809620  Mem. size: 3004  Avg loss: 1.852254  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 106  Epsilon: 0.807720  Mem. size: 3014  Avg loss: 2.378155  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 107  Epsilon: 0.805820  Mem. size: 3024  Avg loss: 2.468958  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 108  Epsilon: 0.803920  Mem. size: 3034  Avg loss: 1.464783  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 109  Epsilon: 0.802020  Mem. size: 3044  Avg loss: 1.908031  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 110  Epsilon: 0.800120  Mem. size: 3054  Avg loss: 2.035010  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 111  Epsilon: 0.798980  Mem. size: 3060  Avg loss: 1.951062  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 112  Epsilon: 0.797080  Mem. size: 3070  Avg loss: 2.184683  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 113  Epsilon: 0.795180  Mem. size: 3080  Avg loss: 2.313032  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 114  Epsilon: 0.793280  Mem. size: 3090  Avg loss: 2.132026  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 115  Epsilon: 0.791570  Mem. size: 3099  Avg loss: 2.023719  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 116  Epsilon: 0.789670  Mem. size: 3109  Avg loss: 2.030757  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 117  Epsilon: 0.787770  Mem. size: 3119  Avg loss: 1.662908  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 118  Epsilon: 0.785870  Mem. size: 3129  Avg loss: 1.246919  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 119  Epsilon: 0.783970  Mem. size: 3139  Avg loss: 1.671237  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 120  Epsilon: 0.782070  Mem. size: 3149  Avg loss: 1.759289  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 121  Epsilon: 0.780170  Mem. size: 3159  Avg loss: 2.069013  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 122  Epsilon: 0.778840  Mem. size: 3166  Avg loss: 1.950582  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 123  Epsilon: 0.776940  Mem. size: 3176  Avg loss: 1.685549  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 124  Epsilon: 0.775420  Mem. size: 3184  Avg loss: 2.055653  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 125  Epsilon: 0.774280  Mem. size: 3190  Avg loss: 1.564054  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 126  Epsilon: 0.773140  Mem. size: 3196  Avg loss: 2.251438  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 127  Epsilon: 0.771240  Mem. size: 3206  Avg loss: 1.735913  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 128  Epsilon: 0.769340  Mem. size: 3216  Avg loss: 1.928674  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 129  Epsilon: 0.768010  Mem. size: 3223  Avg loss: 2.768707  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 130  Epsilon: 0.766110  Mem. size: 3233  Avg loss: 2.035763  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 131  Epsilon: 0.764210  Mem. size: 3243  Avg loss: 2.093608  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 132  Epsilon: 0.762310  Mem. size: 3253  Avg loss: 1.674037  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 133  Epsilon: 0.760410  Mem. size: 3263  Avg loss: 1.745634  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 134  Epsilon: 0.758510  Mem. size: 3273  Avg loss: 2.626446  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 135  Epsilon: 0.756610  Mem. size: 3283  Avg loss: 1.999325  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 136  Epsilon: 0.754710  Mem. size: 3293  Avg loss: 2.018279  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 137  Epsilon: 0.752810  Mem. size: 3303  Avg loss: 1.968937  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 138  Epsilon: 0.750910  Mem. size: 3313  Avg loss: 2.539877  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 139  Epsilon: 0.749010  Mem. size: 3323  Avg loss: 2.129203  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 140  Epsilon: 0.747110  Mem. size: 3333  Avg loss: 2.248300  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 141  Epsilon: 0.745210  Mem. size: 3343  Avg loss: 1.966440  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 142  Epsilon: 0.743310  Mem. size: 3353  Avg loss: 1.453757  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 143  Epsilon: 0.741790  Mem. size: 3361  Avg loss: 2.144437  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 144  Epsilon: 0.739890  Mem. size: 3371  Avg loss: 2.115143  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 145  Epsilon: 0.737990  Mem. size: 3381  Avg loss: 1.682333  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 146  Epsilon: 0.736090  Mem. size: 3391  Avg loss: 2.107345  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 147  Epsilon: 0.735330  Mem. size: 3395  Avg loss: 2.398546  Reward: 6  Achieved goal: True  Optimal num steps: 4  Taken num steps: 4\n",
      "Episode 148  Epsilon: 0.733430  Mem. size: 3405  Avg loss: 1.667336  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 149  Epsilon: 0.731530  Mem. size: 3415  Avg loss: 1.734028  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 150  Epsilon: 0.729630  Mem. size: 3425  Avg loss: 1.640474  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 151  Epsilon: 0.727730  Mem. size: 3435  Avg loss: 1.955026  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 152  Epsilon: 0.725830  Mem. size: 3445  Avg loss: 1.692062  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 153  Epsilon: 0.723930  Mem. size: 3455  Avg loss: 1.886405  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 154  Epsilon: 0.722030  Mem. size: 3465  Avg loss: 1.721321  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 155  Epsilon: 0.721080  Mem. size: 3470  Avg loss: 2.139961  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 156  Epsilon: 0.719180  Mem. size: 3480  Avg loss: 1.597174  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 157  Epsilon: 0.717280  Mem. size: 3490  Avg loss: 1.851814  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 158  Epsilon: 0.715380  Mem. size: 3500  Avg loss: 1.718793  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 159  Epsilon: 0.713480  Mem. size: 3510  Avg loss: 2.043743  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 160  Epsilon: 0.711580  Mem. size: 3520  Avg loss: 1.614846  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 161  Epsilon: 0.709680  Mem. size: 3530  Avg loss: 1.836740  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 162  Epsilon: 0.707780  Mem. size: 3540  Avg loss: 1.773508  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 163  Epsilon: 0.705880  Mem. size: 3550  Avg loss: 1.739563  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 164  Epsilon: 0.704360  Mem. size: 3558  Avg loss: 1.764610  Reward: -1  Achieved goal: True  Optimal num steps: 5  Taken num steps: 8\n",
      "Episode 165  Epsilon: 0.702460  Mem. size: 3568  Avg loss: 1.450217  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 166  Epsilon: 0.700940  Mem. size: 3576  Avg loss: 1.735477  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 167  Epsilon: 0.699040  Mem. size: 3586  Avg loss: 1.708931  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 168  Epsilon: 0.697330  Mem. size: 3595  Avg loss: 1.607605  Reward: -4  Achieved goal: True  Optimal num steps: 4  Taken num steps: 9\n",
      "Episode 169  Epsilon: 0.695430  Mem. size: 3605  Avg loss: 1.387043  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 170  Epsilon: 0.693530  Mem. size: 3615  Avg loss: 1.546677  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 171  Epsilon: 0.691630  Mem. size: 3625  Avg loss: 1.875243  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 172  Epsilon: 0.689730  Mem. size: 3635  Avg loss: 2.088861  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 173  Epsilon: 0.687830  Mem. size: 3645  Avg loss: 1.589104  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 174  Epsilon: 0.687260  Mem. size: 3648  Avg loss: 1.544819  Reward: 7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 3\n",
      "Episode 175  Epsilon: 0.685360  Mem. size: 3658  Avg loss: 2.061671  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 176  Epsilon: 0.683460  Mem. size: 3668  Avg loss: 1.646238  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 177  Epsilon: 0.681750  Mem. size: 3677  Avg loss: 1.892575  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 178  Epsilon: 0.679850  Mem. size: 3687  Avg loss: 1.700416  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 179  Epsilon: 0.677950  Mem. size: 3697  Avg loss: 1.771713  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 180  Epsilon: 0.676050  Mem. size: 3707  Avg loss: 2.060847  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 181  Epsilon: 0.674150  Mem. size: 3717  Avg loss: 1.903877  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 182  Epsilon: 0.672250  Mem. size: 3727  Avg loss: 2.320147  Reward: -5  Achieved goal: True  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 183  Epsilon: 0.670350  Mem. size: 3737  Avg loss: 1.834862  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 184  Epsilon: 0.668450  Mem. size: 3747  Avg loss: 2.309441  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 185  Epsilon: 0.666550  Mem. size: 3757  Avg loss: 2.253054  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 186  Epsilon: 0.665790  Mem. size: 3761  Avg loss: 2.040822  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 187  Epsilon: 0.663890  Mem. size: 3771  Avg loss: 2.087744  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 188  Epsilon: 0.661990  Mem. size: 3781  Avg loss: 2.114114  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 189  Epsilon: 0.660090  Mem. size: 3791  Avg loss: 2.043376  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 190  Epsilon: 0.658190  Mem. size: 3801  Avg loss: 1.680025  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 191  Epsilon: 0.656290  Mem. size: 3811  Avg loss: 2.128907  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 192  Epsilon: 0.654390  Mem. size: 3821  Avg loss: 1.769851  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 193  Epsilon: 0.652490  Mem. size: 3831  Avg loss: 1.775875  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 194  Epsilon: 0.650590  Mem. size: 3841  Avg loss: 1.805382  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 195  Epsilon: 0.648690  Mem. size: 3851  Avg loss: 1.761325  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 196  Epsilon: 0.646790  Mem. size: 3861  Avg loss: 1.875179  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 197  Epsilon: 0.644890  Mem. size: 3871  Avg loss: 2.160532  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 198  Epsilon: 0.642990  Mem. size: 3881  Avg loss: 2.386114  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 199  Epsilon: 0.641090  Mem. size: 3891  Avg loss: 1.796732  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 200  Epsilon: 0.639190  Mem. size: 3901  Avg loss: 2.110619  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 201  Epsilon: 0.637290  Mem. size: 3911  Avg loss: 1.829133  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 202  Epsilon: 0.635390  Mem. size: 3921  Avg loss: 2.032905  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 203  Epsilon: 0.633490  Mem. size: 3931  Avg loss: 1.895234  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 204  Epsilon: 0.631590  Mem. size: 3941  Avg loss: 1.940452  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 205  Epsilon: 0.629690  Mem. size: 3951  Avg loss: 1.437192  Reward: -6  Achieved goal: True  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 206  Epsilon: 0.627790  Mem. size: 3961  Avg loss: 2.656103  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 207  Epsilon: 0.626270  Mem. size: 3969  Avg loss: 1.684812  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 208  Epsilon: 0.624370  Mem. size: 3979  Avg loss: 2.182003  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 209  Epsilon: 0.622470  Mem. size: 3989  Avg loss: 2.055331  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 210  Epsilon: 0.620570  Mem. size: 3999  Avg loss: 1.779859  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 211  Epsilon: 0.618670  Mem. size: 4009  Avg loss: 1.766843  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 212  Epsilon: 0.616770  Mem. size: 4019  Avg loss: 1.857708  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 213  Epsilon: 0.616010  Mem. size: 4023  Avg loss: 1.954889  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 214  Epsilon: 0.614110  Mem. size: 4033  Avg loss: 1.960213  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 215  Epsilon: 0.612590  Mem. size: 4041  Avg loss: 1.799495  Reward: -2  Achieved goal: True  Optimal num steps: 4  Taken num steps: 8\n",
      "Episode 216  Epsilon: 0.611070  Mem. size: 4049  Avg loss: 1.747505  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 217  Epsilon: 0.609170  Mem. size: 4059  Avg loss: 2.039158  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 218  Epsilon: 0.607270  Mem. size: 4069  Avg loss: 2.486881  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 219  Epsilon: 0.605560  Mem. size: 4078  Avg loss: 2.014234  Reward: -4  Achieved goal: True  Optimal num steps: 4  Taken num steps: 9\n",
      "Episode 220  Epsilon: 0.603660  Mem. size: 4088  Avg loss: 2.284969  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 221  Epsilon: 0.601760  Mem. size: 4098  Avg loss: 1.801508  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 222  Epsilon: 0.599860  Mem. size: 4108  Avg loss: 2.143503  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 223  Epsilon: 0.598910  Mem. size: 4113  Avg loss: 2.394369  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 224  Epsilon: 0.597010  Mem. size: 4123  Avg loss: 2.258898  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 225  Epsilon: 0.595110  Mem. size: 4133  Avg loss: 2.149893  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 226  Epsilon: 0.593210  Mem. size: 4143  Avg loss: 2.261567  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 227  Epsilon: 0.591310  Mem. size: 4153  Avg loss: 2.426214  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 228  Epsilon: 0.589410  Mem. size: 4163  Avg loss: 2.043021  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 229  Epsilon: 0.587510  Mem. size: 4173  Avg loss: 2.397691  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 230  Epsilon: 0.586750  Mem. size: 4177  Avg loss: 2.667915  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 231  Epsilon: 0.584850  Mem. size: 4187  Avg loss: 2.246611  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 232  Epsilon: 0.582950  Mem. size: 4197  Avg loss: 2.166966  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 233  Epsilon: 0.581050  Mem. size: 4207  Avg loss: 2.122843  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 234  Epsilon: 0.579150  Mem. size: 4217  Avg loss: 2.571083  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 235  Epsilon: 0.577250  Mem. size: 4227  Avg loss: 1.610868  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 236  Epsilon: 0.575350  Mem. size: 4237  Avg loss: 2.004486  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 237  Epsilon: 0.573450  Mem. size: 4247  Avg loss: 2.299227  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 238  Epsilon: 0.571550  Mem. size: 4257  Avg loss: 1.428306  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 239  Epsilon: 0.570600  Mem. size: 4262  Avg loss: 2.307216  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 240  Epsilon: 0.568700  Mem. size: 4272  Avg loss: 2.425490  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 241  Epsilon: 0.566800  Mem. size: 4282  Avg loss: 2.246606  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 242  Epsilon: 0.564900  Mem. size: 4292  Avg loss: 2.116167  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 243  Epsilon: 0.563380  Mem. size: 4300  Avg loss: 1.971431  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 244  Epsilon: 0.561480  Mem. size: 4310  Avg loss: 2.492154  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 245  Epsilon: 0.559580  Mem. size: 4320  Avg loss: 1.601390  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 246  Epsilon: 0.557680  Mem. size: 4330  Avg loss: 1.938991  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 247  Epsilon: 0.555780  Mem. size: 4340  Avg loss: 1.814144  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 248  Epsilon: 0.553880  Mem. size: 4350  Avg loss: 1.827970  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 249  Epsilon: 0.551980  Mem. size: 4360  Avg loss: 2.103407  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 250  Epsilon: 0.550080  Mem. size: 4370  Avg loss: 1.917094  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 251  Epsilon: 0.548750  Mem. size: 4377  Avg loss: 1.779505  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 252  Epsilon: 0.547800  Mem. size: 4382  Avg loss: 1.880143  Reward: 4  Achieved goal: True  Optimal num steps: 4  Taken num steps: 5\n",
      "Episode 253  Epsilon: 0.547040  Mem. size: 4386  Avg loss: 2.289060  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 254  Epsilon: 0.545140  Mem. size: 4396  Avg loss: 2.039552  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 255  Epsilon: 0.543240  Mem. size: 4406  Avg loss: 2.204341  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 256  Epsilon: 0.541340  Mem. size: 4416  Avg loss: 2.205059  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 257  Epsilon: 0.539440  Mem. size: 4426  Avg loss: 2.005035  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 258  Epsilon: 0.537540  Mem. size: 4436  Avg loss: 2.246894  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 259  Epsilon: 0.535640  Mem. size: 4446  Avg loss: 1.750795  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 260  Epsilon: 0.533740  Mem. size: 4456  Avg loss: 2.643838  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 261  Epsilon: 0.531840  Mem. size: 4466  Avg loss: 2.017741  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 262  Epsilon: 0.530700  Mem. size: 4472  Avg loss: 3.129645  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 263  Epsilon: 0.528800  Mem. size: 4482  Avg loss: 1.566074  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 264  Epsilon: 0.526900  Mem. size: 4492  Avg loss: 2.366122  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 265  Epsilon: 0.525000  Mem. size: 4502  Avg loss: 1.855125  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 266  Epsilon: 0.523100  Mem. size: 4512  Avg loss: 2.027643  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 267  Epsilon: 0.521200  Mem. size: 4522  Avg loss: 1.818243  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 268  Epsilon: 0.519680  Mem. size: 4530  Avg loss: 1.946683  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 269  Epsilon: 0.517970  Mem. size: 4539  Avg loss: 2.182927  Reward: -3  Achieved goal: True  Optimal num steps: 5  Taken num steps: 9\n",
      "Episode 270  Epsilon: 0.516070  Mem. size: 4549  Avg loss: 2.109903  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 271  Epsilon: 0.514170  Mem. size: 4559  Avg loss: 2.099787  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 272  Epsilon: 0.512270  Mem. size: 4569  Avg loss: 2.388069  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 273  Epsilon: 0.510750  Mem. size: 4577  Avg loss: 2.091014  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 274  Epsilon: 0.508850  Mem. size: 4587  Avg loss: 1.972209  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 275  Epsilon: 0.506950  Mem. size: 4597  Avg loss: 2.472726  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 276  Epsilon: 0.505430  Mem. size: 4605  Avg loss: 1.832708  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 277  Epsilon: 0.503530  Mem. size: 4615  Avg loss: 2.143871  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 278  Epsilon: 0.501630  Mem. size: 4625  Avg loss: 2.118084  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 279  Epsilon: 0.499730  Mem. size: 4635  Avg loss: 2.209476  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 280  Epsilon: 0.497830  Mem. size: 4645  Avg loss: 2.161216  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 281  Epsilon: 0.495930  Mem. size: 4655  Avg loss: 1.934502  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 282  Epsilon: 0.494030  Mem. size: 4665  Avg loss: 2.368197  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 283  Epsilon: 0.492130  Mem. size: 4675  Avg loss: 2.574196  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 284  Epsilon: 0.490230  Mem. size: 4685  Avg loss: 2.147768  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 285  Epsilon: 0.488330  Mem. size: 4695  Avg loss: 2.316490  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 286  Epsilon: 0.486430  Mem. size: 4705  Avg loss: 1.882345  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 287  Epsilon: 0.484530  Mem. size: 4715  Avg loss: 2.213028  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 288  Epsilon: 0.483200  Mem. size: 4722  Avg loss: 1.460257  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 289  Epsilon: 0.481300  Mem. size: 4732  Avg loss: 1.901378  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 290  Epsilon: 0.479400  Mem. size: 4742  Avg loss: 1.876660  Reward: -6  Achieved goal: True  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 291  Epsilon: 0.477500  Mem. size: 4752  Avg loss: 2.022938  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 292  Epsilon: 0.475600  Mem. size: 4762  Avg loss: 2.212569  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 293  Epsilon: 0.473700  Mem. size: 4772  Avg loss: 1.872832  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 294  Epsilon: 0.471800  Mem. size: 4782  Avg loss: 1.701781  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 295  Epsilon: 0.469900  Mem. size: 4792  Avg loss: 1.983312  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 296  Epsilon: 0.468000  Mem. size: 4802  Avg loss: 2.123505  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 297  Epsilon: 0.466100  Mem. size: 4812  Avg loss: 1.951938  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 298  Epsilon: 0.464200  Mem. size: 4822  Avg loss: 1.591646  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 299  Epsilon: 0.462490  Mem. size: 4831  Avg loss: 2.374672  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 300  Epsilon: 0.460590  Mem. size: 4841  Avg loss: 2.061080  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 301  Epsilon: 0.458690  Mem. size: 4851  Avg loss: 1.590341  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 302  Epsilon: 0.456790  Mem. size: 4861  Avg loss: 1.624944  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 303  Epsilon: 0.454890  Mem. size: 4871  Avg loss: 1.909955  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 304  Epsilon: 0.452990  Mem. size: 4881  Avg loss: 2.250345  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 305  Epsilon: 0.451090  Mem. size: 4891  Avg loss: 1.668664  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 306  Epsilon: 0.449190  Mem. size: 4901  Avg loss: 1.714342  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 307  Epsilon: 0.447290  Mem. size: 4911  Avg loss: 1.990596  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 308  Epsilon: 0.445390  Mem. size: 4921  Avg loss: 2.473037  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 309  Epsilon: 0.443490  Mem. size: 4931  Avg loss: 2.134241  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 310  Epsilon: 0.441590  Mem. size: 4941  Avg loss: 2.014828  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 311  Epsilon: 0.439690  Mem. size: 4951  Avg loss: 2.012084  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 312  Epsilon: 0.437790  Mem. size: 4961  Avg loss: 2.418566  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 313  Epsilon: 0.435890  Mem. size: 4971  Avg loss: 2.231826  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 314  Epsilon: 0.433990  Mem. size: 4981  Avg loss: 2.335349  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 315  Epsilon: 0.432090  Mem. size: 4991  Avg loss: 1.974189  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 316  Epsilon: 0.430190  Mem. size: 5001  Avg loss: 1.825351  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 317  Epsilon: 0.428290  Mem. size: 5011  Avg loss: 1.627445  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 318  Epsilon: 0.426390  Mem. size: 5021  Avg loss: 1.602557  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 319  Epsilon: 0.424490  Mem. size: 5031  Avg loss: 1.876201  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 320  Epsilon: 0.422590  Mem. size: 5041  Avg loss: 2.026175  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 321  Epsilon: 0.420690  Mem. size: 5051  Avg loss: 2.341864  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 322  Epsilon: 0.418790  Mem. size: 5061  Avg loss: 2.266447  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 323  Epsilon: 0.416890  Mem. size: 5071  Avg loss: 1.929628  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 324  Epsilon: 0.414990  Mem. size: 5081  Avg loss: 2.312017  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 325  Epsilon: 0.413090  Mem. size: 5091  Avg loss: 1.919662  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 326  Epsilon: 0.411190  Mem. size: 5101  Avg loss: 1.748174  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 327  Epsilon: 0.409290  Mem. size: 5111  Avg loss: 2.105292  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 328  Epsilon: 0.407390  Mem. size: 5121  Avg loss: 2.525173  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 329  Epsilon: 0.405490  Mem. size: 5131  Avg loss: 2.177928  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 330  Epsilon: 0.403590  Mem. size: 5141  Avg loss: 2.329943  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 331  Epsilon: 0.401690  Mem. size: 5151  Avg loss: 2.157475  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 332  Epsilon: 0.399790  Mem. size: 5161  Avg loss: 1.856116  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 333  Epsilon: 0.397890  Mem. size: 5171  Avg loss: 2.177394  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 334  Epsilon: 0.395990  Mem. size: 5181  Avg loss: 2.112205  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 335  Epsilon: 0.394090  Mem. size: 5191  Avg loss: 2.150818  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 336  Epsilon: 0.392380  Mem. size: 5200  Avg loss: 2.017376  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 337  Epsilon: 0.390670  Mem. size: 5209  Avg loss: 1.947569  Reward: -4  Achieved goal: True  Optimal num steps: 4  Taken num steps: 9\n",
      "Episode 338  Epsilon: 0.390100  Mem. size: 5212  Avg loss: 1.966372  Reward: 7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 3\n",
      "Episode 339  Epsilon: 0.388390  Mem. size: 5221  Avg loss: 1.907084  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 340  Epsilon: 0.387250  Mem. size: 5227  Avg loss: 1.993816  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 341  Epsilon: 0.385350  Mem. size: 5237  Avg loss: 2.010719  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 342  Epsilon: 0.383450  Mem. size: 5247  Avg loss: 1.927406  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 343  Epsilon: 0.381550  Mem. size: 5257  Avg loss: 2.211713  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 344  Epsilon: 0.379650  Mem. size: 5267  Avg loss: 2.202328  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 345  Epsilon: 0.377750  Mem. size: 5277  Avg loss: 1.656327  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 346  Epsilon: 0.375850  Mem. size: 5287  Avg loss: 1.572046  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 347  Epsilon: 0.373950  Mem. size: 5297  Avg loss: 2.054684  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 348  Epsilon: 0.372050  Mem. size: 5307  Avg loss: 2.367058  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 349  Epsilon: 0.370150  Mem. size: 5317  Avg loss: 2.249015  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 350  Epsilon: 0.368250  Mem. size: 5327  Avg loss: 2.211519  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 351  Epsilon: 0.366350  Mem. size: 5337  Avg loss: 2.367797  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 352  Epsilon: 0.364450  Mem. size: 5347  Avg loss: 2.055186  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 353  Epsilon: 0.363500  Mem. size: 5352  Avg loss: 2.395678  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 354  Epsilon: 0.361600  Mem. size: 5362  Avg loss: 2.133302  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 355  Epsilon: 0.359700  Mem. size: 5372  Avg loss: 3.002689  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 356  Epsilon: 0.357800  Mem. size: 5382  Avg loss: 2.050963  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 357  Epsilon: 0.355900  Mem. size: 5392  Avg loss: 2.556850  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 358  Epsilon: 0.354000  Mem. size: 5402  Avg loss: 2.086618  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 359  Epsilon: 0.352100  Mem. size: 5412  Avg loss: 1.686186  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 360  Epsilon: 0.350200  Mem. size: 5422  Avg loss: 1.970944  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 361  Epsilon: 0.348300  Mem. size: 5432  Avg loss: 1.800056  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 362  Epsilon: 0.346400  Mem. size: 5442  Avg loss: 2.109214  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 363  Epsilon: 0.344500  Mem. size: 5452  Avg loss: 1.881984  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 364  Epsilon: 0.342600  Mem. size: 5462  Avg loss: 2.088471  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 365  Epsilon: 0.340700  Mem. size: 5472  Avg loss: 2.651128  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 366  Epsilon: 0.338800  Mem. size: 5482  Avg loss: 1.682774  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 367  Epsilon: 0.337280  Mem. size: 5490  Avg loss: 2.135311  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 368  Epsilon: 0.335950  Mem. size: 5497  Avg loss: 1.721981  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 369  Epsilon: 0.334050  Mem. size: 5507  Avg loss: 2.324782  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 370  Epsilon: 0.332150  Mem. size: 5517  Avg loss: 2.365051  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 371  Epsilon: 0.330250  Mem. size: 5527  Avg loss: 2.323130  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 372  Epsilon: 0.328350  Mem. size: 5537  Avg loss: 2.851360  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 373  Epsilon: 0.326450  Mem. size: 5547  Avg loss: 2.569472  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 374  Epsilon: 0.324550  Mem. size: 5557  Avg loss: 1.693416  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 375  Epsilon: 0.322650  Mem. size: 5567  Avg loss: 2.493718  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 376  Epsilon: 0.320750  Mem. size: 5577  Avg loss: 1.436595  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 377  Epsilon: 0.319040  Mem. size: 5586  Avg loss: 1.984136  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 378  Epsilon: 0.317520  Mem. size: 5594  Avg loss: 2.463526  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 379  Epsilon: 0.315620  Mem. size: 5604  Avg loss: 2.373012  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 380  Epsilon: 0.314860  Mem. size: 5608  Avg loss: 1.996463  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 381  Epsilon: 0.312960  Mem. size: 5618  Avg loss: 1.686281  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 382  Epsilon: 0.311060  Mem. size: 5628  Avg loss: 2.095176  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 383  Epsilon: 0.309160  Mem. size: 5638  Avg loss: 2.132796  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 384  Epsilon: 0.307260  Mem. size: 5648  Avg loss: 2.211688  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 385  Epsilon: 0.305930  Mem. size: 5655  Avg loss: 2.313638  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 386  Epsilon: 0.304030  Mem. size: 5665  Avg loss: 2.457999  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 387  Epsilon: 0.302130  Mem. size: 5675  Avg loss: 2.442380  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 388  Epsilon: 0.300610  Mem. size: 5683  Avg loss: 1.984152  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 389  Epsilon: 0.298710  Mem. size: 5693  Avg loss: 2.579294  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 390  Epsilon: 0.297570  Mem. size: 5699  Avg loss: 2.241359  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 391  Epsilon: 0.295670  Mem. size: 5709  Avg loss: 1.498767  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 392  Epsilon: 0.293770  Mem. size: 5719  Avg loss: 2.170573  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 393  Epsilon: 0.291870  Mem. size: 5729  Avg loss: 2.496069  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 394  Epsilon: 0.289970  Mem. size: 5739  Avg loss: 1.958879  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 395  Epsilon: 0.288830  Mem. size: 5745  Avg loss: 2.115049  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 396  Epsilon: 0.286930  Mem. size: 5755  Avg loss: 2.544591  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 397  Epsilon: 0.285030  Mem. size: 5765  Avg loss: 2.803061  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 398  Epsilon: 0.283130  Mem. size: 5775  Avg loss: 1.614838  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 399  Epsilon: 0.281230  Mem. size: 5785  Avg loss: 2.655480  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400  Epsilon: 0.279330  Mem. size: 5795  Avg loss: 1.812073  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 401  Epsilon: 0.277430  Mem. size: 5805  Avg loss: 2.394807  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 402  Epsilon: 0.275530  Mem. size: 5815  Avg loss: 2.164093  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 403  Epsilon: 0.273630  Mem. size: 5825  Avg loss: 1.982643  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 404  Epsilon: 0.271730  Mem. size: 5835  Avg loss: 2.264445  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 405  Epsilon: 0.269830  Mem. size: 5845  Avg loss: 1.857031  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 406  Epsilon: 0.267930  Mem. size: 5855  Avg loss: 2.155998  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 407  Epsilon: 0.266030  Mem. size: 5865  Avg loss: 1.809383  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 408  Epsilon: 0.264130  Mem. size: 5875  Avg loss: 2.657549  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 409  Epsilon: 0.262230  Mem. size: 5885  Avg loss: 1.578133  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 410  Epsilon: 0.260330  Mem. size: 5895  Avg loss: 2.780976  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 411  Epsilon: 0.258620  Mem. size: 5904  Avg loss: 2.420424  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 412  Epsilon: 0.256720  Mem. size: 5914  Avg loss: 1.762408  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 413  Epsilon: 0.255770  Mem. size: 5919  Avg loss: 2.320792  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 414  Epsilon: 0.253870  Mem. size: 5929  Avg loss: 2.099490  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 415  Epsilon: 0.251970  Mem. size: 5939  Avg loss: 2.215831  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 416  Epsilon: 0.250070  Mem. size: 5949  Avg loss: 2.367810  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 417  Epsilon: 0.248170  Mem. size: 5959  Avg loss: 2.553780  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 418  Epsilon: 0.246270  Mem. size: 5969  Avg loss: 1.893356  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 419  Epsilon: 0.245510  Mem. size: 5973  Avg loss: 1.960118  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 420  Epsilon: 0.243610  Mem. size: 5983  Avg loss: 2.081892  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 421  Epsilon: 0.241710  Mem. size: 5993  Avg loss: 2.440453  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 422  Epsilon: 0.239810  Mem. size: 6003  Avg loss: 2.180298  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 423  Epsilon: 0.237910  Mem. size: 6013  Avg loss: 2.304587  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 424  Epsilon: 0.236010  Mem. size: 6023  Avg loss: 2.492260  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 425  Epsilon: 0.234110  Mem. size: 6033  Avg loss: 2.454535  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 426  Epsilon: 0.232210  Mem. size: 6043  Avg loss: 1.895679  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 427  Epsilon: 0.230310  Mem. size: 6053  Avg loss: 2.726465  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 428  Epsilon: 0.228410  Mem. size: 6063  Avg loss: 2.705810  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 429  Epsilon: 0.226700  Mem. size: 6072  Avg loss: 2.235966  Reward: -4  Achieved goal: True  Optimal num steps: 4  Taken num steps: 9\n",
      "Episode 430  Epsilon: 0.224800  Mem. size: 6082  Avg loss: 2.637492  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 431  Epsilon: 0.222900  Mem. size: 6092  Avg loss: 1.969146  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 432  Epsilon: 0.221000  Mem. size: 6102  Avg loss: 2.778914  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 433  Epsilon: 0.219100  Mem. size: 6112  Avg loss: 2.170730  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 434  Epsilon: 0.217580  Mem. size: 6120  Avg loss: 2.682966  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 435  Epsilon: 0.215680  Mem. size: 6130  Avg loss: 1.922674  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 436  Epsilon: 0.213780  Mem. size: 6140  Avg loss: 2.685022  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 437  Epsilon: 0.213020  Mem. size: 6144  Avg loss: 2.856764  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 438  Epsilon: 0.211500  Mem. size: 6152  Avg loss: 2.011330  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 439  Epsilon: 0.209600  Mem. size: 6162  Avg loss: 3.358404  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 440  Epsilon: 0.207700  Mem. size: 6172  Avg loss: 2.571934  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 441  Epsilon: 0.205800  Mem. size: 6182  Avg loss: 2.189723  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 442  Epsilon: 0.203900  Mem. size: 6192  Avg loss: 2.235741  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 443  Epsilon: 0.202000  Mem. size: 6202  Avg loss: 2.349874  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 444  Epsilon: 0.200100  Mem. size: 6212  Avg loss: 3.072334  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 445  Epsilon: 0.198580  Mem. size: 6220  Avg loss: 2.700811  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 446  Epsilon: 0.196680  Mem. size: 6230  Avg loss: 2.644239  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 447  Epsilon: 0.194780  Mem. size: 6240  Avg loss: 2.178882  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 448  Epsilon: 0.192880  Mem. size: 6250  Avg loss: 2.977270  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 449  Epsilon: 0.190980  Mem. size: 6260  Avg loss: 2.456820  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 450  Epsilon: 0.189080  Mem. size: 6270  Avg loss: 2.843581  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 451  Epsilon: 0.187180  Mem. size: 6280  Avg loss: 3.328116  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 452  Epsilon: 0.185280  Mem. size: 6290  Avg loss: 2.386184  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 453  Epsilon: 0.183380  Mem. size: 6300  Avg loss: 1.913485  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 454  Epsilon: 0.181480  Mem. size: 6310  Avg loss: 2.694413  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 455  Epsilon: 0.179580  Mem. size: 6320  Avg loss: 2.283394  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 456  Epsilon: 0.177680  Mem. size: 6330  Avg loss: 1.966027  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 457  Epsilon: 0.175780  Mem. size: 6340  Avg loss: 2.199749  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 458  Epsilon: 0.173880  Mem. size: 6350  Avg loss: 1.860507  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 459  Epsilon: 0.171980  Mem. size: 6360  Avg loss: 1.975656  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 460  Epsilon: 0.171030  Mem. size: 6365  Avg loss: 2.491118  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 461  Epsilon: 0.169130  Mem. size: 6375  Avg loss: 2.820770  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 462  Epsilon: 0.167230  Mem. size: 6385  Avg loss: 2.772315  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 463  Epsilon: 0.165330  Mem. size: 6395  Avg loss: 2.702771  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 464  Epsilon: 0.163430  Mem. size: 6405  Avg loss: 3.167957  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 465  Epsilon: 0.161530  Mem. size: 6415  Avg loss: 2.504904  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 466  Epsilon: 0.159630  Mem. size: 6425  Avg loss: 2.750951  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 467  Epsilon: 0.157730  Mem. size: 6435  Avg loss: 2.868249  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 468  Epsilon: 0.155830  Mem. size: 6445  Avg loss: 2.064354  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 469  Epsilon: 0.153930  Mem. size: 6455  Avg loss: 2.900891  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 470  Epsilon: 0.152030  Mem. size: 6465  Avg loss: 2.440622  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 471  Epsilon: 0.150130  Mem. size: 6475  Avg loss: 3.218815  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 472  Epsilon: 0.148230  Mem. size: 6485  Avg loss: 2.649197  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 473  Epsilon: 0.146330  Mem. size: 6495  Avg loss: 2.775265  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 474  Epsilon: 0.144430  Mem. size: 6505  Avg loss: 2.964712  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 475  Epsilon: 0.142530  Mem. size: 6515  Avg loss: 2.518503  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 476  Epsilon: 0.140820  Mem. size: 6524  Avg loss: 2.853399  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 477  Epsilon: 0.138920  Mem. size: 6534  Avg loss: 3.200016  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 478  Epsilon: 0.137020  Mem. size: 6544  Avg loss: 2.903459  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 479  Epsilon: 0.135120  Mem. size: 6554  Avg loss: 2.425205  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 480  Epsilon: 0.133220  Mem. size: 6564  Avg loss: 3.126477  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 481  Epsilon: 0.131890  Mem. size: 6571  Avg loss: 2.929800  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 482  Epsilon: 0.129990  Mem. size: 6581  Avg loss: 2.520061  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 483  Epsilon: 0.128090  Mem. size: 6591  Avg loss: 2.335235  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 484  Epsilon: 0.126190  Mem. size: 6601  Avg loss: 1.972275  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 485  Epsilon: 0.124290  Mem. size: 6611  Avg loss: 2.132902  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 486  Epsilon: 0.123150  Mem. size: 6617  Avg loss: 2.039242  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 487  Epsilon: 0.121250  Mem. size: 6627  Avg loss: 2.432472  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 488  Epsilon: 0.119730  Mem. size: 6635  Avg loss: 2.120269  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 489  Epsilon: 0.117830  Mem. size: 6645  Avg loss: 2.162592  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 490  Epsilon: 0.115930  Mem. size: 6655  Avg loss: 2.356562  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 491  Epsilon: 0.114030  Mem. size: 6665  Avg loss: 2.617223  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 492  Epsilon: 0.112130  Mem. size: 6675  Avg loss: 2.673669  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 493  Epsilon: 0.110230  Mem. size: 6685  Avg loss: 2.465368  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 494  Epsilon: 0.108330  Mem. size: 6695  Avg loss: 3.313963  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 495  Epsilon: 0.106430  Mem. size: 6705  Avg loss: 2.476922  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 496  Epsilon: 0.104530  Mem. size: 6715  Avg loss: 2.429075  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 497  Epsilon: 0.103770  Mem. size: 6719  Avg loss: 2.585887  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 498  Epsilon: 0.101870  Mem. size: 6729  Avg loss: 2.127354  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 499  Epsilon: 0.100160  Mem. size: 6738  Avg loss: 2.543850  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 500  Epsilon: 0.098260  Mem. size: 6748  Avg loss: 2.130327  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 501  Epsilon: 0.096360  Mem. size: 6758  Avg loss: 2.224470  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 502  Epsilon: 0.094460  Mem. size: 6768  Avg loss: 2.549827  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 503  Epsilon: 0.093130  Mem. size: 6775  Avg loss: 2.273076  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 504  Epsilon: 0.091230  Mem. size: 6785  Avg loss: 2.668049  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 505  Epsilon: 0.089330  Mem. size: 6795  Avg loss: 2.458714  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 506  Epsilon: 0.087430  Mem. size: 6805  Avg loss: 2.564725  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 507  Epsilon: 0.085530  Mem. size: 6815  Avg loss: 2.370099  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 508  Epsilon: 0.083630  Mem. size: 6825  Avg loss: 2.360704  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 509  Epsilon: 0.081730  Mem. size: 6835  Avg loss: 2.248870  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 510  Epsilon: 0.079830  Mem. size: 6845  Avg loss: 2.430469  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 511  Epsilon: 0.077930  Mem. size: 6855  Avg loss: 1.935752  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 512  Epsilon: 0.076030  Mem. size: 6865  Avg loss: 3.034407  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 513  Epsilon: 0.074130  Mem. size: 6875  Avg loss: 2.124259  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 514  Epsilon: 0.072230  Mem. size: 6885  Avg loss: 2.488822  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 515  Epsilon: 0.070330  Mem. size: 6895  Avg loss: 2.700278  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 516  Epsilon: 0.068430  Mem. size: 6905  Avg loss: 2.205180  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 517  Epsilon: 0.066910  Mem. size: 6913  Avg loss: 2.336291  Reward: -2  Achieved goal: True  Optimal num steps: 4  Taken num steps: 8\n",
      "Episode 518  Epsilon: 0.066150  Mem. size: 6917  Avg loss: 2.253559  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 519  Epsilon: 0.064250  Mem. size: 6927  Avg loss: 2.293756  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 520  Epsilon: 0.062540  Mem. size: 6936  Avg loss: 2.712946  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 521  Epsilon: 0.060640  Mem. size: 6946  Avg loss: 2.689125  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 522  Epsilon: 0.058740  Mem. size: 6956  Avg loss: 3.009783  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 523  Epsilon: 0.056840  Mem. size: 6966  Avg loss: 1.975807  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 524  Epsilon: 0.054940  Mem. size: 6976  Avg loss: 2.832793  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 525  Epsilon: 0.053040  Mem. size: 6986  Avg loss: 2.145627  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 526  Epsilon: 0.051140  Mem. size: 6996  Avg loss: 2.022301  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 527  Epsilon: 0.050000  Mem. size: 7006  Avg loss: 2.700018  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 528  Epsilon: 0.050000  Mem. size: 7016  Avg loss: 2.246011  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 529  Epsilon: 0.050000  Mem. size: 7026  Avg loss: 2.163697  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 530  Epsilon: 0.050000  Mem. size: 7036  Avg loss: 2.538112  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 531  Epsilon: 0.050000  Mem. size: 7046  Avg loss: 2.777585  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 532  Epsilon: 0.050000  Mem. size: 7056  Avg loss: 2.043936  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 533  Epsilon: 0.050000  Mem. size: 7066  Avg loss: 2.349088  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 534  Epsilon: 0.050000  Mem. size: 7075  Avg loss: 2.140173  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 535  Epsilon: 0.050000  Mem. size: 7085  Avg loss: 2.805112  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 536  Epsilon: 0.050000  Mem. size: 7095  Avg loss: 2.554198  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 537  Epsilon: 0.050000  Mem. size: 7105  Avg loss: 2.948614  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 538  Epsilon: 0.050000  Mem. size: 7115  Avg loss: 2.638311  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 539  Epsilon: 0.050000  Mem. size: 7125  Avg loss: 2.260492  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 540  Epsilon: 0.050000  Mem. size: 7135  Avg loss: 2.484499  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 541  Epsilon: 0.050000  Mem. size: 7144  Avg loss: 2.409324  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 542  Epsilon: 0.050000  Mem. size: 7149  Avg loss: 3.696086  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 543  Epsilon: 0.050000  Mem. size: 7159  Avg loss: 2.271096  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 544  Epsilon: 0.050000  Mem. size: 7163  Avg loss: 3.209155  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 545  Epsilon: 0.050000  Mem. size: 7173  Avg loss: 2.477762  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 546  Epsilon: 0.050000  Mem. size: 7178  Avg loss: 2.715160  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 547  Epsilon: 0.050000  Mem. size: 7188  Avg loss: 2.089931  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 548  Epsilon: 0.050000  Mem. size: 7198  Avg loss: 2.709275  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 549  Epsilon: 0.050000  Mem. size: 7205  Avg loss: 3.124315  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 550  Epsilon: 0.050000  Mem. size: 7211  Avg loss: 2.309474  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 551  Epsilon: 0.050000  Mem. size: 7214  Avg loss: 3.353134  Reward: 7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 3\n",
      "Episode 552  Epsilon: 0.050000  Mem. size: 7219  Avg loss: 2.053436  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 553  Epsilon: 0.050000  Mem. size: 7229  Avg loss: 2.360909  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 554  Epsilon: 0.050000  Mem. size: 7239  Avg loss: 2.076630  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 555  Epsilon: 0.050000  Mem. size: 7249  Avg loss: 2.701752  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 556  Epsilon: 0.050000  Mem. size: 7259  Avg loss: 2.784925  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 557  Epsilon: 0.050000  Mem. size: 7268  Avg loss: 3.054683  Reward: -4  Achieved goal: True  Optimal num steps: 4  Taken num steps: 9\n",
      "Episode 558  Epsilon: 0.050000  Mem. size: 7278  Avg loss: 2.611436  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 559  Epsilon: 0.050000  Mem. size: 7288  Avg loss: 2.399669  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 560  Epsilon: 0.050000  Mem. size: 7298  Avg loss: 2.398180  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 561  Epsilon: 0.050000  Mem. size: 7308  Avg loss: 3.156207  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 562  Epsilon: 0.050000  Mem. size: 7318  Avg loss: 2.316666  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 563  Epsilon: 0.050000  Mem. size: 7328  Avg loss: 2.307100  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 564  Epsilon: 0.050000  Mem. size: 7338  Avg loss: 2.805529  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 565  Epsilon: 0.050000  Mem. size: 7347  Avg loss: 2.352134  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 566  Epsilon: 0.050000  Mem. size: 7357  Avg loss: 2.800969  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 567  Epsilon: 0.050000  Mem. size: 7367  Avg loss: 2.948633  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 568  Epsilon: 0.050000  Mem. size: 7377  Avg loss: 2.372645  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 569  Epsilon: 0.050000  Mem. size: 7387  Avg loss: 2.753812  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 570  Epsilon: 0.050000  Mem. size: 7397  Avg loss: 2.865981  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 571  Epsilon: 0.050000  Mem. size: 7407  Avg loss: 2.581453  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 572  Epsilon: 0.050000  Mem. size: 7417  Avg loss: 2.644313  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 573  Epsilon: 0.050000  Mem. size: 7427  Avg loss: 2.538017  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 574  Epsilon: 0.050000  Mem. size: 7437  Avg loss: 2.929029  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 575  Epsilon: 0.050000  Mem. size: 7447  Avg loss: 3.571522  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 576  Epsilon: 0.050000  Mem. size: 7457  Avg loss: 2.001633  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 577  Epsilon: 0.050000  Mem. size: 7467  Avg loss: 2.508492  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 578  Epsilon: 0.050000  Mem. size: 7477  Avg loss: 2.354259  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 579  Epsilon: 0.050000  Mem. size: 7487  Avg loss: 2.617201  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 580  Epsilon: 0.050000  Mem. size: 7497  Avg loss: 2.472119  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 581  Epsilon: 0.050000  Mem. size: 7507  Avg loss: 2.823541  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 582  Epsilon: 0.050000  Mem. size: 7517  Avg loss: 2.796106  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 583  Epsilon: 0.050000  Mem. size: 7527  Avg loss: 2.353934  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 584  Epsilon: 0.050000  Mem. size: 7537  Avg loss: 2.573797  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 585  Epsilon: 0.050000  Mem. size: 7547  Avg loss: 3.251741  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 586  Epsilon: 0.050000  Mem. size: 7557  Avg loss: 2.573731  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 587  Epsilon: 0.050000  Mem. size: 7567  Avg loss: 2.514441  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 588  Epsilon: 0.050000  Mem. size: 7577  Avg loss: 2.334702  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 589  Epsilon: 0.050000  Mem. size: 7584  Avg loss: 2.416299  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 590  Epsilon: 0.050000  Mem. size: 7594  Avg loss: 2.354329  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 591  Epsilon: 0.050000  Mem. size: 7604  Avg loss: 2.888543  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 592  Epsilon: 0.050000  Mem. size: 7614  Avg loss: 2.392860  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 593  Epsilon: 0.050000  Mem. size: 7620  Avg loss: 2.484103  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 594  Epsilon: 0.050000  Mem. size: 7625  Avg loss: 3.451315  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 595  Epsilon: 0.050000  Mem. size: 7635  Avg loss: 3.030217  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 596  Epsilon: 0.050000  Mem. size: 7641  Avg loss: 1.840905  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 597  Epsilon: 0.050000  Mem. size: 7651  Avg loss: 2.434850  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 598  Epsilon: 0.050000  Mem. size: 7661  Avg loss: 2.215362  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 599  Epsilon: 0.050000  Mem. size: 7671  Avg loss: 2.388973  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 600  Epsilon: 0.050000  Mem. size: 7681  Avg loss: 2.894634  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 601  Epsilon: 0.050000  Mem. size: 7691  Avg loss: 2.045353  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 602  Epsilon: 0.050000  Mem. size: 7701  Avg loss: 2.112995  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 603  Epsilon: 0.050000  Mem. size: 7711  Avg loss: 2.794840  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 604  Epsilon: 0.050000  Mem. size: 7721  Avg loss: 2.666638  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 605  Epsilon: 0.050000  Mem. size: 7731  Avg loss: 2.956629  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 606  Epsilon: 0.050000  Mem. size: 7741  Avg loss: 2.383024  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 607  Epsilon: 0.050000  Mem. size: 7751  Avg loss: 2.254021  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 608  Epsilon: 0.050000  Mem. size: 7761  Avg loss: 2.689663  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 609  Epsilon: 0.050000  Mem. size: 7771  Avg loss: 2.282298  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 610  Epsilon: 0.050000  Mem. size: 7781  Avg loss: 2.279659  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 611  Epsilon: 0.050000  Mem. size: 7791  Avg loss: 2.556046  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 612  Epsilon: 0.050000  Mem. size: 7801  Avg loss: 2.894715  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 613  Epsilon: 0.050000  Mem. size: 7807  Avg loss: 1.799926  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 614  Epsilon: 0.050000  Mem. size: 7814  Avg loss: 2.978225  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 615  Epsilon: 0.050000  Mem. size: 7824  Avg loss: 2.700639  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 616  Epsilon: 0.050000  Mem. size: 7834  Avg loss: 2.484009  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 617  Epsilon: 0.050000  Mem. size: 7838  Avg loss: 2.864738  Reward: 6  Achieved goal: True  Optimal num steps: 4  Taken num steps: 4\n",
      "Episode 618  Epsilon: 0.050000  Mem. size: 7848  Avg loss: 1.917242  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 619  Epsilon: 0.050000  Mem. size: 7858  Avg loss: 2.881445  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 620  Epsilon: 0.050000  Mem. size: 7868  Avg loss: 2.211076  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 621  Epsilon: 0.050000  Mem. size: 7878  Avg loss: 2.553939  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 622  Epsilon: 0.050000  Mem. size: 7888  Avg loss: 2.716252  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 623  Epsilon: 0.050000  Mem. size: 7898  Avg loss: 2.048084  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 624  Epsilon: 0.050000  Mem. size: 7908  Avg loss: 2.393614  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 625  Epsilon: 0.050000  Mem. size: 7918  Avg loss: 3.079791  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 626  Epsilon: 0.050000  Mem. size: 7928  Avg loss: 2.780020  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 627  Epsilon: 0.050000  Mem. size: 7938  Avg loss: 3.161913  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 628  Epsilon: 0.050000  Mem. size: 7948  Avg loss: 2.426570  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 629  Epsilon: 0.050000  Mem. size: 7958  Avg loss: 2.477002  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 630  Epsilon: 0.050000  Mem. size: 7968  Avg loss: 2.427716  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 631  Epsilon: 0.050000  Mem. size: 7977  Avg loss: 2.876934  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 632  Epsilon: 0.050000  Mem. size: 7987  Avg loss: 2.401367  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 633  Epsilon: 0.050000  Mem. size: 7997  Avg loss: 2.342132  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 634  Epsilon: 0.050000  Mem. size: 8007  Avg loss: 3.208337  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 635  Epsilon: 0.050000  Mem. size: 8017  Avg loss: 2.551829  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 636  Epsilon: 0.050000  Mem. size: 8027  Avg loss: 2.884001  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 637  Epsilon: 0.050000  Mem. size: 8037  Avg loss: 3.530937  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 638  Epsilon: 0.050000  Mem. size: 8043  Avg loss: 2.685371  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 639  Epsilon: 0.050000  Mem. size: 8053  Avg loss: 2.923385  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 640  Epsilon: 0.050000  Mem. size: 8063  Avg loss: 2.689187  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 641  Epsilon: 0.050000  Mem. size: 8073  Avg loss: 2.447643  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 642  Epsilon: 0.050000  Mem. size: 8083  Avg loss: 2.795890  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 643  Epsilon: 0.050000  Mem. size: 8093  Avg loss: 2.028645  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 644  Epsilon: 0.050000  Mem. size: 8103  Avg loss: 2.893391  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 645  Epsilon: 0.050000  Mem. size: 8113  Avg loss: 2.567822  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 646  Epsilon: 0.050000  Mem. size: 8123  Avg loss: 3.281945  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 647  Epsilon: 0.050000  Mem. size: 8133  Avg loss: 3.482984  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 648  Epsilon: 0.050000  Mem. size: 8143  Avg loss: 2.758346  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 649  Epsilon: 0.050000  Mem. size: 8153  Avg loss: 3.258461  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 650  Epsilon: 0.050000  Mem. size: 8163  Avg loss: 2.866585  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 651  Epsilon: 0.050000  Mem. size: 8170  Avg loss: 3.121470  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 652  Epsilon: 0.050000  Mem. size: 8180  Avg loss: 2.803559  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 653  Epsilon: 0.050000  Mem. size: 8190  Avg loss: 2.768985  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 654  Epsilon: 0.050000  Mem. size: 8200  Avg loss: 3.038296  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 655  Epsilon: 0.050000  Mem. size: 8210  Avg loss: 2.792443  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 656  Epsilon: 0.050000  Mem. size: 8220  Avg loss: 2.348431  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 657  Epsilon: 0.050000  Mem. size: 8230  Avg loss: 4.046483  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 658  Epsilon: 0.050000  Mem. size: 8238  Avg loss: 3.030699  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 659  Epsilon: 0.050000  Mem. size: 8248  Avg loss: 3.120138  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 660  Epsilon: 0.050000  Mem. size: 8258  Avg loss: 3.316329  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 661  Epsilon: 0.050000  Mem. size: 8268  Avg loss: 2.239820  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 662  Epsilon: 0.050000  Mem. size: 8278  Avg loss: 2.340866  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 663  Epsilon: 0.050000  Mem. size: 8288  Avg loss: 2.635207  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 664  Epsilon: 0.050000  Mem. size: 8298  Avg loss: 2.623414  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 665  Epsilon: 0.050000  Mem. size: 8308  Avg loss: 2.446954  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 666  Epsilon: 0.050000  Mem. size: 8318  Avg loss: 2.728507  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 667  Epsilon: 0.050000  Mem. size: 8328  Avg loss: 3.249480  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 668  Epsilon: 0.050000  Mem. size: 8338  Avg loss: 2.134157  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 669  Epsilon: 0.050000  Mem. size: 8346  Avg loss: 2.920599  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 670  Epsilon: 0.050000  Mem. size: 8356  Avg loss: 2.295321  Reward: -5  Achieved goal: True  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 671  Epsilon: 0.050000  Mem. size: 8366  Avg loss: 2.442772  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 672  Epsilon: 0.050000  Mem. size: 8376  Avg loss: 2.988432  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 673  Epsilon: 0.050000  Mem. size: 8386  Avg loss: 2.097188  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 674  Epsilon: 0.050000  Mem. size: 8392  Avg loss: 2.960328  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 675  Epsilon: 0.050000  Mem. size: 8402  Avg loss: 2.639873  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 676  Epsilon: 0.050000  Mem. size: 8412  Avg loss: 2.767346  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 677  Epsilon: 0.050000  Mem. size: 8422  Avg loss: 2.675487  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 678  Epsilon: 0.050000  Mem. size: 8428  Avg loss: 3.347706  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 679  Epsilon: 0.050000  Mem. size: 8438  Avg loss: 2.907161  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 680  Epsilon: 0.050000  Mem. size: 8448  Avg loss: 2.374060  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 681  Epsilon: 0.050000  Mem. size: 8458  Avg loss: 3.204889  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 682  Epsilon: 0.050000  Mem. size: 8468  Avg loss: 2.869766  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 683  Epsilon: 0.050000  Mem. size: 8478  Avg loss: 2.598279  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 684  Epsilon: 0.050000  Mem. size: 8488  Avg loss: 2.269208  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 685  Epsilon: 0.050000  Mem. size: 8498  Avg loss: 2.463200  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 686  Epsilon: 0.050000  Mem. size: 8506  Avg loss: 3.068744  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 687  Epsilon: 0.050000  Mem. size: 8511  Avg loss: 2.192116  Reward: 4  Achieved goal: True  Optimal num steps: 4  Taken num steps: 5\n",
      "Episode 688  Epsilon: 0.050000  Mem. size: 8521  Avg loss: 2.814415  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 689  Epsilon: 0.050000  Mem. size: 8530  Avg loss: 2.366464  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 690  Epsilon: 0.050000  Mem. size: 8540  Avg loss: 3.150889  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 691  Epsilon: 0.050000  Mem. size: 8550  Avg loss: 3.357063  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 692  Epsilon: 0.050000  Mem. size: 8560  Avg loss: 3.288372  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 693  Epsilon: 0.050000  Mem. size: 8570  Avg loss: 2.219324  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 694  Epsilon: 0.050000  Mem. size: 8580  Avg loss: 3.078247  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 695  Epsilon: 0.050000  Mem. size: 8590  Avg loss: 3.271293  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 696  Epsilon: 0.050000  Mem. size: 8600  Avg loss: 2.379755  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 697  Epsilon: 0.050000  Mem. size: 8610  Avg loss: 2.272848  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 698  Epsilon: 0.050000  Mem. size: 8620  Avg loss: 3.139858  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 699  Epsilon: 0.050000  Mem. size: 8630  Avg loss: 2.515225  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 700  Epsilon: 0.050000  Mem. size: 8640  Avg loss: 3.220225  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 701  Epsilon: 0.050000  Mem. size: 8650  Avg loss: 2.751198  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 702  Epsilon: 0.050000  Mem. size: 8660  Avg loss: 1.955578  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 703  Epsilon: 0.050000  Mem. size: 8670  Avg loss: 2.460442  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 704  Epsilon: 0.050000  Mem. size: 8674  Avg loss: 2.598539  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 705  Epsilon: 0.050000  Mem. size: 8684  Avg loss: 2.351003  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 706  Epsilon: 0.050000  Mem. size: 8694  Avg loss: 2.951295  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 707  Epsilon: 0.050000  Mem. size: 8704  Avg loss: 2.918430  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 708  Epsilon: 0.050000  Mem. size: 8714  Avg loss: 2.436426  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 709  Epsilon: 0.050000  Mem. size: 8719  Avg loss: 3.405958  Reward: 3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 5\n",
      "Episode 710  Epsilon: 0.050000  Mem. size: 8729  Avg loss: 2.598403  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 711  Epsilon: 0.050000  Mem. size: 8738  Avg loss: 3.266133  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 712  Epsilon: 0.050000  Mem. size: 8748  Avg loss: 2.934588  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 713  Epsilon: 0.050000  Mem. size: 8758  Avg loss: 2.609305  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 714  Epsilon: 0.050000  Mem. size: 8768  Avg loss: 3.042376  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 715  Epsilon: 0.050000  Mem. size: 8778  Avg loss: 3.332410  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 716  Epsilon: 0.050000  Mem. size: 8788  Avg loss: 2.219237  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 717  Epsilon: 0.050000  Mem. size: 8798  Avg loss: 2.679638  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 718  Epsilon: 0.050000  Mem. size: 8808  Avg loss: 2.743794  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 719  Epsilon: 0.050000  Mem. size: 8818  Avg loss: 3.721248  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 720  Epsilon: 0.050000  Mem. size: 8828  Avg loss: 3.170061  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 721  Epsilon: 0.050000  Mem. size: 8838  Avg loss: 2.611566  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 722  Epsilon: 0.050000  Mem. size: 8848  Avg loss: 2.283885  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 723  Epsilon: 0.050000  Mem. size: 8852  Avg loss: 4.244029  Reward: 6  Achieved goal: True  Optimal num steps: 4  Taken num steps: 4\n",
      "Episode 724  Epsilon: 0.050000  Mem. size: 8862  Avg loss: 3.079108  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 725  Epsilon: 0.050000  Mem. size: 8872  Avg loss: 3.093011  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 726  Epsilon: 0.050000  Mem. size: 8882  Avg loss: 2.987375  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 727  Epsilon: 0.050000  Mem. size: 8891  Avg loss: 3.217724  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 728  Epsilon: 0.050000  Mem. size: 8901  Avg loss: 3.523052  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 729  Epsilon: 0.050000  Mem. size: 8907  Avg loss: 3.027175  Reward: 1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 6\n",
      "Episode 730  Epsilon: 0.050000  Mem. size: 8917  Avg loss: 2.273647  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 731  Epsilon: 0.050000  Mem. size: 8927  Avg loss: 3.127842  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 732  Epsilon: 0.050000  Mem. size: 8937  Avg loss: 2.516366  Reward: -7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 733  Epsilon: 0.050000  Mem. size: 8947  Avg loss: 2.369573  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 734  Epsilon: 0.050000  Mem. size: 8957  Avg loss: 3.085306  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 735  Epsilon: 0.050000  Mem. size: 8967  Avg loss: 2.403349  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 736  Epsilon: 0.050000  Mem. size: 8975  Avg loss: 3.599147  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 737  Epsilon: 0.050000  Mem. size: 8985  Avg loss: 2.606271  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 738  Epsilon: 0.050000  Mem. size: 8995  Avg loss: 3.118836  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 739  Epsilon: 0.050000  Mem. size: 9005  Avg loss: 2.738147  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 740  Epsilon: 0.050000  Mem. size: 9015  Avg loss: 2.856882  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 741  Epsilon: 0.050000  Mem. size: 9025  Avg loss: 2.192977  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 742  Epsilon: 0.050000  Mem. size: 9035  Avg loss: 2.328655  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 743  Epsilon: 0.050000  Mem. size: 9045  Avg loss: 3.236220  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 744  Epsilon: 0.050000  Mem. size: 9055  Avg loss: 2.634616  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 745  Epsilon: 0.050000  Mem. size: 9064  Avg loss: 2.960047  Reward: -4  Achieved goal: True  Optimal num steps: 4  Taken num steps: 9\n",
      "Episode 746  Epsilon: 0.050000  Mem. size: 9074  Avg loss: 3.454222  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 747  Epsilon: 0.050000  Mem. size: 9084  Avg loss: 3.507639  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 748  Epsilon: 0.050000  Mem. size: 9094  Avg loss: 2.830858  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 749  Epsilon: 0.050000  Mem. size: 9102  Avg loss: 3.288637  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 750  Epsilon: 0.050000  Mem. size: 9112  Avg loss: 2.687003  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 751  Epsilon: 0.050000  Mem. size: 9122  Avg loss: 2.674048  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 752  Epsilon: 0.050000  Mem. size: 9132  Avg loss: 2.395392  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 753  Epsilon: 0.050000  Mem. size: 9142  Avg loss: 3.447954  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 754  Epsilon: 0.050000  Mem. size: 9151  Avg loss: 2.721344  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 755  Epsilon: 0.050000  Mem. size: 9160  Avg loss: 2.391896  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 756  Epsilon: 0.050000  Mem. size: 9170  Avg loss: 3.071664  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 757  Epsilon: 0.050000  Mem. size: 9180  Avg loss: 2.796702  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 758  Epsilon: 0.050000  Mem. size: 9190  Avg loss: 2.206955  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 759  Epsilon: 0.050000  Mem. size: 9200  Avg loss: 2.764986  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 760  Epsilon: 0.050000  Mem. size: 9210  Avg loss: 2.829688  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 761  Epsilon: 0.050000  Mem. size: 9214  Avg loss: 1.998784  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 762  Epsilon: 0.050000  Mem. size: 9224  Avg loss: 2.850176  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 763  Epsilon: 0.050000  Mem. size: 9234  Avg loss: 2.699518  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 764  Epsilon: 0.050000  Mem. size: 9244  Avg loss: 3.213559  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 765  Epsilon: 0.050000  Mem. size: 9252  Avg loss: 2.557485  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 766  Epsilon: 0.050000  Mem. size: 9262  Avg loss: 2.721454  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 767  Epsilon: 0.050000  Mem. size: 9272  Avg loss: 2.940363  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 768  Epsilon: 0.050000  Mem. size: 9281  Avg loss: 3.087709  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 769  Epsilon: 0.050000  Mem. size: 9291  Avg loss: 2.672343  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 770  Epsilon: 0.050000  Mem. size: 9301  Avg loss: 3.091172  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 771  Epsilon: 0.050000  Mem. size: 9311  Avg loss: 2.604151  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 772  Epsilon: 0.050000  Mem. size: 9321  Avg loss: 3.340863  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 773  Epsilon: 0.050000  Mem. size: 9330  Avg loss: 2.304873  Reward: -4  Achieved goal: True  Optimal num steps: 4  Taken num steps: 9\n",
      "Episode 774  Epsilon: 0.050000  Mem. size: 9340  Avg loss: 2.742436  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 775  Epsilon: 0.050000  Mem. size: 9350  Avg loss: 2.920583  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 776  Epsilon: 0.050000  Mem. size: 9360  Avg loss: 3.065319  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 777  Epsilon: 0.050000  Mem. size: 9364  Avg loss: 2.357261  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 778  Epsilon: 0.050000  Mem. size: 9374  Avg loss: 2.795754  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 779  Epsilon: 0.050000  Mem. size: 9384  Avg loss: 3.393148  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 780  Epsilon: 0.050000  Mem. size: 9393  Avg loss: 3.367042  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 781  Epsilon: 0.050000  Mem. size: 9403  Avg loss: 2.690642  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 782  Epsilon: 0.050000  Mem. size: 9406  Avg loss: 2.463468  Reward: 7  Achieved goal: True  Optimal num steps: 3  Taken num steps: 3\n",
      "Episode 783  Epsilon: 0.050000  Mem. size: 9415  Avg loss: 2.912258  Reward: -5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 9\n",
      "Episode 784  Epsilon: 0.050000  Mem. size: 9425  Avg loss: 3.578238  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 785  Epsilon: 0.050000  Mem. size: 9435  Avg loss: 2.673301  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 786  Epsilon: 0.050000  Mem. size: 9444  Avg loss: 2.350419  Reward: -3  Achieved goal: True  Optimal num steps: 5  Taken num steps: 9\n",
      "Episode 787  Epsilon: 0.050000  Mem. size: 9454  Avg loss: 3.370290  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 788  Epsilon: 0.050000  Mem. size: 9464  Avg loss: 3.538640  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 789  Epsilon: 0.050000  Mem. size: 9474  Avg loss: 3.581384  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 790  Epsilon: 0.050000  Mem. size: 9484  Avg loss: 2.613705  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 791  Epsilon: 0.050000  Mem. size: 9494  Avg loss: 2.108987  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 792  Epsilon: 0.050000  Mem. size: 9504  Avg loss: 2.587734  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 793  Epsilon: 0.050000  Mem. size: 9514  Avg loss: 2.790786  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 794  Epsilon: 0.050000  Mem. size: 9524  Avg loss: 2.961683  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 795  Epsilon: 0.050000  Mem. size: 9534  Avg loss: 2.727637  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 796  Epsilon: 0.050000  Mem. size: 9544  Avg loss: 2.908755  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 797  Epsilon: 0.050000  Mem. size: 9554  Avg loss: 2.318062  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 798  Epsilon: 0.050000  Mem. size: 9564  Avg loss: 3.192994  Reward: -6  Achieved goal: True  Optimal num steps: 4  Taken num steps: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 799  Epsilon: 0.050000  Mem. size: 9574  Avg loss: 2.523876  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 800  Epsilon: 0.050000  Mem. size: 9584  Avg loss: 2.953140  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 801  Epsilon: 0.050000  Mem. size: 9594  Avg loss: 2.962401  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 802  Epsilon: 0.050000  Mem. size: 9604  Avg loss: 3.317397  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 803  Epsilon: 0.050000  Mem. size: 9614  Avg loss: 3.445110  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 804  Epsilon: 0.050000  Mem. size: 9624  Avg loss: 3.127547  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 805  Epsilon: 0.050000  Mem. size: 9634  Avg loss: 3.310721  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 806  Epsilon: 0.050000  Mem. size: 9644  Avg loss: 3.284129  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 807  Epsilon: 0.050000  Mem. size: 9652  Avg loss: 2.861893  Reward: -3  Achieved goal: True  Optimal num steps: 3  Taken num steps: 8\n",
      "Episode 808  Epsilon: 0.050000  Mem. size: 9662  Avg loss: 2.916163  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 809  Epsilon: 0.050000  Mem. size: 9670  Avg loss: 2.938493  Reward: -2  Achieved goal: True  Optimal num steps: 4  Taken num steps: 8\n",
      "Episode 810  Epsilon: 0.050000  Mem. size: 9680  Avg loss: 3.422746  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 811  Epsilon: 0.050000  Mem. size: 9690  Avg loss: 2.812538  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 812  Epsilon: 0.050000  Mem. size: 9694  Avg loss: 3.701833  Reward: 5  Achieved goal: True  Optimal num steps: 3  Taken num steps: 4\n",
      "Episode 813  Epsilon: 0.050000  Mem. size: 9704  Avg loss: 3.402122  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 814  Epsilon: 0.050000  Mem. size: 9714  Avg loss: 3.052173  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 815  Epsilon: 0.050000  Mem. size: 9724  Avg loss: 4.026458  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 816  Epsilon: 0.050000  Mem. size: 9731  Avg loss: 3.560262  Reward: -1  Achieved goal: True  Optimal num steps: 3  Taken num steps: 7\n",
      "Episode 817  Epsilon: 0.050000  Mem. size: 9741  Avg loss: 2.496513  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n",
      "Episode 818  Epsilon: 0.050000  Mem. size: 9751  Avg loss: 2.656084  Reward: -15  Achieved goal: False  Optimal num steps: 5  Taken num steps: 10\n",
      "Episode 819  Epsilon: 0.050000  Mem. size: 9761  Avg loss: 2.287540  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 820  Epsilon: 0.050000  Mem. size: 9771  Avg loss: 2.861032  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 821  Epsilon: 0.050000  Mem. size: 9781  Avg loss: 2.792355  Reward: -15  Achieved goal: False  Optimal num steps: 3  Taken num steps: 10\n",
      "Episode 822  Epsilon: 0.050000  Mem. size: 9791  Avg loss: 2.999262  Reward: -15  Achieved goal: False  Optimal num steps: 4  Taken num steps: 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-387-19086f0d1872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_eps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtotal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_rew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m#     history.append(ep_history)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtrain_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max ep rew'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max ep rew'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_rew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-386-c0b4dd538a4b>\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(ep, total_step)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#             print('step: {}'.format(total_step))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#             print('mem: {}'.format(len(agent.memory)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mmb_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mep_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-379-a391e5b875fe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m                         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                         \u001b[0moutputs_beh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropogate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                         \u001b[0mnext_state_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_beh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                         \u001b[0moutputs_tar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropogate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-383-7e0167233280>\u001b[0m in \u001b[0;36mpropogate\u001b[0;34m(gnn, state)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_props\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpredecessors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predecessors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mnode_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_props\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredecessors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked_goal_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mnode_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/web-crawler-drl-gnn/nervenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, send_input, get_output, predecessors, goal)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# Get messages of each node ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;31m# Aggregate pred. edges -----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0maggregates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/web-crawler-drl-gnn/nervenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# assert nodes.shape == (self.num_nodes, self.hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;31m# assert messages.shape == (self.num_nodes, self.message_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    828\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[1;32m    829\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = DQNAgent()\n",
    "\n",
    "print('\\n---------- Warmup initiated ----------\\n')\n",
    "warmup_step = 0\n",
    "warmup_ep = 0\n",
    "warmup_info = defaultdict(list)\n",
    "while warmup_step < num_warmup_steps:\n",
    "    warmup_step, ep_rew, achieved_goal, opt_steps, steps_taken = warmup_episode(warmup_step)\n",
    "    warmup_ep += 1\n",
    "    warmup_info['episode reward'].append(ep_rew)\n",
    "    warmup_info['achieved goal'].append(achieved_goal)\n",
    "    warmup_info['opt steps'].append(opt_steps)\n",
    "    warmup_info['steps taken'].append(steps_taken)\n",
    "print('Warmup stage summary:  Memory size: {}  Avg ep rew: {:.2f}  Achieved goal ratio: {:.2f}  Avg opt num steps: {:.2f}  Avg num steps taken: {:.2f}'.format(len(agent.memory),\n",
    "                                                                                                                             np.array(warmup_info['episode reward']).mean(),\n",
    "                                                                                                                             np.array(warmup_info['achieved goal']).sum() / warmup_ep,\n",
    "                                                                                                                             np.array(warmup_info['opt steps']).mean(),\n",
    "                                                                                                                             np.array(warmup_info['steps taken']).mean()))\n",
    "\n",
    "print('\\n---------- Training initiated ----------\\n')\n",
    "total_step = 0\n",
    "train_info = {}\n",
    "train_info['max ep rew'] = float('-inf')\n",
    "train_info['episode of best reward'] = 0\n",
    "train_info['min ep loss'] = float('inf')\n",
    "train_info['episode of best loss'] = 0\n",
    "history = []\n",
    "for ep in range(num_eps):\n",
    "    total_step, ep_history, loss, ep_rew = run_episode(ep, total_step)\n",
    "#     history.append(ep_history)\n",
    "    train_info['max ep rew'] = max(train_info['max ep rew'], ep_rew)\n",
    "    if train_info['max ep rew'] == ep_rew:\n",
    "        train_info['episode of best reward'] = ep+1 \n",
    "    train_info['min ep loss'] = min(train_info['min ep loss'], loss)\n",
    "    if train_info['min ep loss'] == loss:\n",
    "        train_info['episode of best loss'] = ep+1 \n",
    "print('\\nTraining summary:  Max episode reward: {} at episode {},  Min episode loss: {:.3f} at episode {}'.format(train_info['max ep rew'], \n",
    "                                                                                                                      train_info['episode of best reward'], \n",
    "                                                                                                                      train_info['min ep loss'], \n",
    "                                                                                                                      train_info['episode of best loss']))                                                                                   \n",
    "  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vis. an episodes graphs\n",
    "def vis_ep(ep_graphs):\n",
    "    for G in ep_graphs:\n",
    "        nx.draw_kamada_kawai(G, with_labels=True)\n",
    "        plt.show()\n",
    "# vis_ep(history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
