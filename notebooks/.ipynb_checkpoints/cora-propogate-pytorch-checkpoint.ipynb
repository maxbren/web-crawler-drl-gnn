{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Propogate test with cora (to make sure it works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 5  # Num nodes\n",
    "f = 12  # Num input feats\n",
    "h = f  # Hidden state for node size\n",
    "m = 6  # Message size\n",
    "num_class = 1  # ITS REGRESSION RIGHT NOW, CHANGE IT BACK FOR CORA\n",
    "o = num_class  # Output size\n",
    "num_props = 3\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input I need:\n",
    "1. The graph (cora is undirected so I will just make each edge a 2-way) in networkx\n",
    "2. predecessors list since this is a static graph and i need it for the aggregate\n",
    "3. N x h that is updated every prop because its a static graph so this is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make graph\n",
    "node_dict = {}\n",
    "node_feats = np.zeros(shape=(N, f))\n",
    "for i in range(N):\n",
    "    feat = np.random.uniform(0, 1, f)\n",
    "    node_feats[i] = feat\n",
    "    node_dict[i] = feat\n",
    "G = nx.complete_graph(node_dict, nx.DiGraph())\n",
    "nx.set_node_attributes(G, node_dict, 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(G)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make numpy matrix of N x f\n",
    "# node_feats = np.zeros(shape=(N, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "predecessors = []\n",
    "for node in G.nodes:\n",
    "    predecessors.append(list(G.predecessors(node)))\n",
    "assert len(predecessors) == N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input: (N x h) which is all nodes hidden states\n",
    "# Outut: (N x m) all nodes messages\n",
    "class MessageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MessageModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(h, m),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, nodes):\n",
    "        assert nodes.shape == (N, h)\n",
    "        messages = self.model(nodes)\n",
    "        assert messages.shape == (N, m)\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input: (N, m) agg messages\n",
    "# Output: (N, h) new hidden states for nodes\n",
    "class UpdateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UpdateModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(m, h),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, messages):\n",
    "        assert messages.shape == (N, m)\n",
    "        updates = self.model(messages)\n",
    "        assert updates.shape == (N, h)\n",
    "        return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input: (N, h)  updated node hidden states\n",
    "# Output: (N, o)  outputs for each node (softmax on classes)\n",
    "class OutputModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OutputModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(h, o),\n",
    "#             nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, nodes):\n",
    "        assert nodes.shape == (N, h)\n",
    "        outputs = self.model(nodes)\n",
    "        assert outputs.shape == (N, o)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph NN block\n",
    "class GNBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNBlock, self).__init__()\n",
    "        self.message_model = MessageModel()\n",
    "        self.update_model = UpdateModel()\n",
    "        self.output_model = OutputModel()\n",
    "    \n",
    "    # Input: (N x m)\n",
    "    # Output: (N x m)\n",
    "    def aggregate(self, predecessors, messages):\n",
    "        agg = []\n",
    "        # Collect all in predecessors for each node, if a node has no preds then just 0s for it\n",
    "        for preds in predecessors:\n",
    "            if len(preds) > 0:\n",
    "                in_mess = messages[preds, :]\n",
    "                assert in_mess.shape == (len(preds), m) or in_mess.shape == (m,)  # if one in-node\n",
    "#                 agg_in_mess = agg_func(in_mess)\n",
    "                agg_in_mess = torch.mean(in_mess, dim=0)\n",
    "                assert agg_in_mess.shape == (m,)\n",
    "                agg.append(agg_in_mess)\n",
    "            else:\n",
    "                agg.append(torch.zeros(m))\n",
    "        # Stack\n",
    "#         stack = np.stack(agg)\n",
    "        stack = torch.stack(agg)\n",
    "        assert stack.shape == (N, m)\n",
    "        return stack\n",
    "        \n",
    "    # Propogate\n",
    "    def forward(self, node_states, get_output):\n",
    "        # Get messages of each node ----\n",
    "        messages = self.message_model(node_states)\n",
    "        # Aggregate pred. edges -----\n",
    "        aggregates = self.aggregate(predecessors, messages)\n",
    "        # Get Updates for each node hidden state ---------\n",
    "        updates = self.update_model(aggregates)\n",
    "        # Get outputs if need to\n",
    "        if get_output:\n",
    "            outputs = self.output_model(updates)\n",
    "            return updates, outputs\n",
    "        return updates, None\n",
    "    \n",
    "    # Outputs: (N, o) tensor\n",
    "    def backward(self, outputs):\n",
    "        loss = outputs.sum()\n",
    "        loss.backward()\n",
    "        return loss.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make GNBlock\n",
    "gnn = GNBlock()\n",
    "optimizer = optim.Adam(gnn.parameters(), lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(node_feats):\n",
    "    # Every time you run through a minibatch, zero out the grad\n",
    "    optimizer.zero_grad()\n",
    "    # Convert node_feats np to node_states torch tensor\n",
    "    node_states = torch.tensor(node_feats).float()\n",
    "    for p in range(num_props):\n",
    "        node_states, outputs = gnn(node_states, p == num_props-1)\n",
    "    # Train\n",
    "    loss = gnn.backward(outputs)\n",
    "    optimizer.step()\n",
    "    print('loss: {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4241909980773926\n",
      "loss: 0.19192063808441162\n",
      "loss: -0.04645250737667084\n",
      "loss: -0.293054461479187\n",
      "loss: -0.5538526177406311\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    run_epoch(node_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
