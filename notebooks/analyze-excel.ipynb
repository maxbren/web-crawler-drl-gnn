{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('../run-data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.drop(len(data)-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.to_excel('../run-data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time_taken(m)</th>\n",
       "      <th>eval_ach_goal_perc</th>\n",
       "      <th>eval_avg_opt_steps</th>\n",
       "      <th>eval_avg_steps_taken</th>\n",
       "      <th>E_num_train_rollouts</th>\n",
       "      <th>E_rollout_length</th>\n",
       "      <th>E_eval_freq</th>\n",
       "      <th>E_eval_num_eps</th>\n",
       "      <th>E_max_ep_steps</th>\n",
       "      <th>E_ignore_internal_nodes</th>\n",
       "      <th>...</th>\n",
       "      <th>A_learning_rate</th>\n",
       "      <th>A_clip_grads</th>\n",
       "      <th>A_gradient_clip</th>\n",
       "      <th>A_value_loss_coef</th>\n",
       "      <th>A_critic_agg_weight</th>\n",
       "      <th>O_num_agents</th>\n",
       "      <th>O_reach_goal_rew</th>\n",
       "      <th>O_not_reach_goal_rew</th>\n",
       "      <th>O_node_feat_type</th>\n",
       "      <th>O_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.081955</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.98</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.794598</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>3.82</td>\n",
       "      <td>14.36</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.325292</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>3.91</td>\n",
       "      <td>15.26</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.440943</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>3.97</td>\n",
       "      <td>14.54</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.787574</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>3.78</td>\n",
       "      <td>14.50</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_time_taken(m)  eval_ach_goal_perc  eval_avg_opt_steps  \\\n",
       "0            27.081955            0.393939                3.89   \n",
       "1            25.794598            0.383838                3.82   \n",
       "2            24.325292            0.303030                3.91   \n",
       "3            25.440943            0.363636                3.97   \n",
       "4            25.787574            0.393939                3.78   \n",
       "\n",
       "   eval_avg_steps_taken  E_num_train_rollouts  E_rollout_length  E_eval_freq  \\\n",
       "0                 13.98                  1000               128          100   \n",
       "1                 14.36                  1000               128          100   \n",
       "2                 15.26                  1000               128          100   \n",
       "3                 14.54                  1000               128          100   \n",
       "4                 14.50                  1000               128          100   \n",
       "\n",
       "   E_eval_num_eps  E_max_ep_steps  E_ignore_internal_nodes  ...  \\\n",
       "0             100              20                    False  ...   \n",
       "1             100              20                    False  ...   \n",
       "2             100              20                    False  ...   \n",
       "3             100              20                    False  ...   \n",
       "4             100              20                    False  ...   \n",
       "\n",
       "   A_learning_rate  A_clip_grads  A_gradient_clip A_value_loss_coef  \\\n",
       "0            0.001          True                1                 1   \n",
       "1            0.001          True                1                 1   \n",
       "2            0.001          True                1                 1   \n",
       "3            0.001          True                1                 1   \n",
       "4            0.001          True                1                 1   \n",
       "\n",
       "   A_critic_agg_weight  O_num_agents  O_reach_goal_rew  O_not_reach_goal_rew  \\\n",
       "0                 0.75             8                 5                    -5   \n",
       "1                 0.75             8                 5                    -5   \n",
       "2                 0.75             8                 5                    -5   \n",
       "3                 0.75             8                 5                    -5   \n",
       "4                 0.75             8                 5                    -5   \n",
       "\n",
       "   O_node_feat_type  O_data  \n",
       "0                 1  medium  \n",
       "1                 1  medium  \n",
       "2                 1  medium  \n",
       "3                 1  medium  \n",
       "4                 1  medium  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary conclusions:\n",
    "- goal_opt == 2 performs better (probably)\n",
    "- learning_rate == 1e-3 performs much better than the other two\n",
    "- value_loss_coef == 1.0 performs better (probably)\n",
    "- critic_agg_Weight == anything lol\n",
    "- num_props == 1 is much better\n",
    "- minibatch_size == 16 or 32, but 32 is faster\n",
    "- node_hidden_size == 32\n",
    "- message_size == 32\n",
    "- rollout_length == 256 (or more) for performance, but 128 for faster\n",
    "- optimization_epochs == 10\n",
    "- node_feat_type == 1 slightly better than 0\n",
    "- reach_goal_rew == 5 (try closer to 0)\n",
    "- not_reach_goal_rew == -5 (try closer to 0)\n",
    "- gae_tau == 0.9 (try lower)\n",
    "- entropy_weight == 0.01\n",
    "- ppo_ratio_clip == 0.3 (try higher)\n",
    "- discount == 0.95 (try lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time_taken(m)</th>\n",
       "      <th>eval_avg_steps_taken</th>\n",
       "      <th>M_node_hidden_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.840180</td>\n",
       "      <td>5.41</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.824455</td>\n",
       "      <td>5.49</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.828436</td>\n",
       "      <td>5.25</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.726999</td>\n",
       "      <td>5.57</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.708798</td>\n",
       "      <td>5.14</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.889116</td>\n",
       "      <td>5.26</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.802397</td>\n",
       "      <td>5.34</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.549956</td>\n",
       "      <td>5.45</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.925751</td>\n",
       "      <td>5.82</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.555275</td>\n",
       "      <td>5.32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.436293</td>\n",
       "      <td>5.04</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.642309</td>\n",
       "      <td>5.38</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.384897</td>\n",
       "      <td>5.43</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.443789</td>\n",
       "      <td>5.08</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.541112</td>\n",
       "      <td>5.35</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.569354</td>\n",
       "      <td>4.72</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.677382</td>\n",
       "      <td>5.35</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.815030</td>\n",
       "      <td>5.34</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.085590</td>\n",
       "      <td>5.33</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.869618</td>\n",
       "      <td>5.07</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8.795882</td>\n",
       "      <td>4.97</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.429446</td>\n",
       "      <td>5.44</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.831362</td>\n",
       "      <td>5.29</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.781769</td>\n",
       "      <td>5.22</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.513672</td>\n",
       "      <td>5.02</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.676078</td>\n",
       "      <td>5.58</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.755880</td>\n",
       "      <td>5.07</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.876632</td>\n",
       "      <td>5.59</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.813202</td>\n",
       "      <td>5.70</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.880007</td>\n",
       "      <td>5.19</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>8.414701</td>\n",
       "      <td>6.78</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>8.456223</td>\n",
       "      <td>6.61</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>8.609181</td>\n",
       "      <td>6.37</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>8.661308</td>\n",
       "      <td>6.87</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>8.664599</td>\n",
       "      <td>6.15</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>8.876733</td>\n",
       "      <td>5.26</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>9.000850</td>\n",
       "      <td>5.05</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>8.714516</td>\n",
       "      <td>5.43</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>8.315251</td>\n",
       "      <td>6.99</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>8.676966</td>\n",
       "      <td>6.89</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8.474640</td>\n",
       "      <td>6.82</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8.667973</td>\n",
       "      <td>4.97</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8.902987</td>\n",
       "      <td>5.90</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8.685394</td>\n",
       "      <td>5.71</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8.536542</td>\n",
       "      <td>5.96</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>8.660560</td>\n",
       "      <td>5.60</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8.513004</td>\n",
       "      <td>5.53</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8.804542</td>\n",
       "      <td>5.51</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8.790446</td>\n",
       "      <td>5.66</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>8.597911</td>\n",
       "      <td>5.24</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9.235539</td>\n",
       "      <td>5.43</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>11.017932</td>\n",
       "      <td>5.06</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>13.200770</td>\n",
       "      <td>5.46</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>10.714784</td>\n",
       "      <td>6.60</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>9.040428</td>\n",
       "      <td>6.05</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8.413787</td>\n",
       "      <td>5.61</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8.660527</td>\n",
       "      <td>5.20</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>8.490648</td>\n",
       "      <td>5.15</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8.828361</td>\n",
       "      <td>5.74</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8.649041</td>\n",
       "      <td>5.36</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_time_taken(m)  eval_avg_steps_taken  M_node_hidden_size\n",
       "0              8.840180                  5.41                  32\n",
       "1              8.824455                  5.49                  32\n",
       "2              8.828436                  5.25                  32\n",
       "3              8.726999                  5.57                  32\n",
       "4              8.708798                  5.14                  32\n",
       "5              8.889116                  5.26                  32\n",
       "6              8.802397                  5.34                  32\n",
       "7              8.549956                  5.45                  32\n",
       "8              8.925751                  5.82                  32\n",
       "9              8.555275                  5.32                  32\n",
       "10             8.436293                  5.04                  32\n",
       "11             8.642309                  5.38                  32\n",
       "12             8.384897                  5.43                  32\n",
       "13             8.443789                  5.08                  32\n",
       "14             8.541112                  5.35                  32\n",
       "15             8.569354                  4.72                  32\n",
       "16             8.677382                  5.35                  32\n",
       "17             8.815030                  5.34                  32\n",
       "18             9.085590                  5.33                  32\n",
       "19             8.869618                  5.07                  32\n",
       "20             8.795882                  4.97                  32\n",
       "21             9.429446                  5.44                  32\n",
       "22             8.831362                  5.29                  32\n",
       "23             8.781769                  5.22                  32\n",
       "24             8.513672                  5.02                  32\n",
       "25             9.676078                  5.58                  32\n",
       "26             8.755880                  5.07                  32\n",
       "27             8.876632                  5.59                  32\n",
       "28             8.813202                  5.70                  32\n",
       "29             8.880007                  5.19                  32\n",
       "..                  ...                   ...                 ...\n",
       "70             8.414701                  6.78                  32\n",
       "71             8.456223                  6.61                  32\n",
       "72             8.609181                  6.37                  32\n",
       "73             8.661308                  6.87                  32\n",
       "74             8.664599                  6.15                  32\n",
       "75             8.876733                  5.26                  32\n",
       "76             9.000850                  5.05                  32\n",
       "77             8.714516                  5.43                  32\n",
       "78             8.315251                  6.99                  32\n",
       "79             8.676966                  6.89                  32\n",
       "80             8.474640                  6.82                  32\n",
       "81             8.667973                  4.97                  32\n",
       "82             8.902987                  5.90                  32\n",
       "83             8.685394                  5.71                  32\n",
       "84             8.536542                  5.96                  32\n",
       "85             8.660560                  5.60                  32\n",
       "86             8.513004                  5.53                  32\n",
       "87             8.804542                  5.51                  32\n",
       "88             8.790446                  5.66                  32\n",
       "89             8.597911                  5.24                  32\n",
       "90             9.235539                  5.43                  32\n",
       "91            11.017932                  5.06                  32\n",
       "92            13.200770                  5.46                  32\n",
       "93            10.714784                  6.60                  32\n",
       "94             9.040428                  6.05                  32\n",
       "95             8.413787                  5.61                  32\n",
       "96             8.660527                  5.20                  32\n",
       "97             8.490648                  5.15                  32\n",
       "98             8.828361                  5.74                  32\n",
       "99             8.649041                  5.36                  32\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['total_time_taken(m)', 'eval_avg_steps_taken', 'M_node_hidden_size']][data['M_node_hidden_size'] == 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max Brenner\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['A_gae_tau'] == 'fully_connected']['total_time_taken(m)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.528"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['M_model_type'] == \"deepmind\"]['eval_avg_steps_taken'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.098000000000003"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['M_model_type'] == 'nervenet']['eval_avg_steps_taken'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.562"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['M_model_type'] == 'fully_connected']['eval_avg_steps_taken'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.901999999999997"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['M_model_type'] == 'no_structure']['eval_avg_steps_taken'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
