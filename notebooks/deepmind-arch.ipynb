{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL FORM FOR DEEPMIND ARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feats = ...\n",
    "edge_feats = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = ...  # Num nodes\n",
    "E = ... # Num edges, * All edges are out-edges for some nodes and in-edges for others\n",
    "f_n = ...  # Num input feats for nodes\n",
    "f_e = ...  # Num input feats for edges\n",
    "h_f = 256  # Hidden state for node size\n",
    "h_e = 32  # Hidden state for edge size\n",
    "num_class = 7\n",
    "o = num_class  # Output size\n",
    "range_train = [0, 140]\n",
    "range_val = [200, 500]\n",
    "range_test = [500, 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-614ec6ea7e82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Need a list of tuples of in-nodes and out-nodes for each edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0medge_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0medge\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0medge_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "# Need a list of tuples of in-nodes and out-nodes for each edge\n",
    "edge_tuples = []\n",
    "for edge in G.edges:\n",
    "    edge_tuples.append((edge[0], edge[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need list of lists of in-edge indxs for each node\n",
    "\n",
    "# MAKE SURE THE EDGES IN EDGE_FEATS IS STORED IN THE SAME ORDER AS IT WILL BE ACCESSED HERE\n",
    "\n",
    "in_edge_list = []\n",
    "for node in G.nodes:\n",
    "    in_edge_list.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: (N, f_n)\n",
    "# Output: (N, h_n)\n",
    "class NodeInputModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NodeInputModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(f_n, h_n),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        \n",
    "    def forward(self, nodes):\n",
    "        assert nodes.shape == (N, f_n)\n",
    "        hidden_states = self.model(nodes)\n",
    "        assert hidden_states.shape == (N, h_n)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: (E, f_e)\n",
    "# Output: (E, h_e)\n",
    "class EdgeInputModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EdgeInputModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(f_e, h_e),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        \n",
    "    def forward(self, edges):\n",
    "        assert edges.shape == (E, f_e)\n",
    "        hidden_states = self.model(edges)\n",
    "        assert hidden_states.shape == (E, h_e)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: (E, h_n + h_n + h_e)  # in node, out node and edge hidden states\n",
    "# Output: (E, h_e)\n",
    "class EdgeUpdateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EdgeUpdateModel, self).__init__()\n",
    "        self.input_shape_cols = h_n + h_n + h_e\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.input_shape_cols, h_e),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "    def forward(self, send_nodes, rec_nodes, edges):\n",
    "        assert send_nodes.shape == (E, h_n)\n",
    "        assert rec_nodes.shape == (E, h_n)\n",
    "        assert edges.shape == (E, h_e)\n",
    "        concat = torch.cat([send_nodes, rec_nodes, edges], dim=1)\n",
    "        assert concat.shape == (E, self.input_shape_cols)\n",
    "        new_edges = self.model(concat)\n",
    "        assert new_edges.shape == (E, h_e)\n",
    "        return new_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: (N, h_n + h_e)  # node, in-edge sum agg\n",
    "# Output: (N, h_n)\n",
    "class NodeUpdateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NodeUpdateModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(h_n + h_e, h_n),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "    def forward(self, nodes, in_edges):\n",
    "        assert nodes.shape == (N, h_n)\n",
    "        assert in_edges.shape == (N, h_e)\n",
    "        concat = torch.cat([nodes, in_edges], dim=1)\n",
    "        assert concat.shape == (N, h_n + h_e)\n",
    "        new_nodes = self.model(concat)\n",
    "        assert new_nodes.shape == (N, h_n)\n",
    "        return new_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: (N, h_n)  updated node hidden states\n",
    "# Output: (N, o)  outputs for each node (softmax on classes)\n",
    "class OutputModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OutputModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(h, o)\n",
    "        )\n",
    "        \n",
    "    def forward(self, nodes):\n",
    "        assert nodes.shape == (N, h_n)\n",
    "        outputs = self.model(nodes)\n",
    "        assert outputs.shape == (N, o)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(layers, ave_grads, max_grads):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems. '''\n",
    "\n",
    "#     plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "#     plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "#     plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "#     plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "#     plt.xlim(left=0, right=len(ave_grads))\n",
    "#     plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "#     plt.xlabel(\"Layers\")\n",
    "#     plt.ylabel(\"average gradient\")\n",
    "#     plt.title(\"Gradient flow\")\n",
    "#     plt.grid(True)\n",
    "#     plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "#                 Line2D([0], [0], color=\"b\", lw=4),\n",
    "#                 Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph NN block\n",
    "class GNBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNBlock, self).__init__()\n",
    "        self.node_input_model = NodeInputModel()\n",
    "        self.edge_input_model = EdgeInputModel()\n",
    "        self.edge_update_model = EdgeUpdateModel()\n",
    "        self.node_update_model = NodeUpdateModel()\n",
    "        self.output_model = OutputModel()\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # edge_tuples contains a list of all edges in terms of in-node indx, and out-node indx\n",
    "    def update_edges(self, edge_tuples, node_states, edge_states):\n",
    "        # Collect in and out nodes\n",
    "        in_nodes = np.zeros(shape=(E, h_n))\n",
    "        out_nodes = np.zeros(shape=(E, h_n))\n",
    "        for e_indx, edge in enumerate(edge_tuples):\n",
    "            in_node = edge[0]\n",
    "            out_node = edge[1]\n",
    "            in_nodes[e_indx] = node_states[in_node]\n",
    "            out_nodes[e_indx] = node_states[out_node]\n",
    "        return self.edge_update_model(in_nodes, out_nodes, edge_states)\n",
    "    \n",
    "    # in_edges_list is a list of lists of the edge indxs of in-edges to a node, if empty then append all zeros\n",
    "    def update_nodes(self, in_edges_list, node_states, edge_states):\n",
    "        agg = []\n",
    "        assert len(in_edges_list) == N\n",
    "        for in_edges in in_edges_list:\n",
    "            if len(in_edges) > 0:\n",
    "                in_edge_states = edge_states[in_edges, :]\n",
    "                assert in_edge_states.shape == (len(in_edges), h_e) or in_edge_states.shape == (h_e,)  # if one\n",
    "                agg_in_edge_states = torch.sum(in_edge_states, dim=0)\n",
    "                assert agg_in_edge_states.shape == (h_e,)\n",
    "                agg.append(agg_in_edge_states)\n",
    "            else:\n",
    "                agg.append(torch.zeros(h_e))\n",
    "        stack = torch.stack(agg)\n",
    "        assert stack.shape == (N, h_e)\n",
    "        return self.node_update_model(node_states, stack)\n",
    "            \n",
    "    # Propogate (THIS ASSUMES THAT THE INITIAL FEATURES ARE SENT IN ON EVERY FIRST PROP OF AN EPOCH)\n",
    "    def forward(self, node_inputs, edge_inputs, edge_tuples, in_edge_list, send_input, get_output):\n",
    "        # Get initial hidden states ------\n",
    "        if send_input:\n",
    "            node_states = self.node_input_model(node_inputs)\n",
    "            edge_states = self.edge_input_model(edge_inputs)\n",
    "        else:\n",
    "            node_states = node_inputs\n",
    "            edge_states = edge_inputs\n",
    "        # Update edges ------\n",
    "        edge_updates = self.update_edges(edge_tuples, node_states, edge_states)\n",
    "        # Update nodes ------\n",
    "        node_updates = self.update_nodes(in_edge_list, node_states, edge_states)\n",
    "        # Get outputs if need to ------\n",
    "        if get_output:\n",
    "            outputs = self.output_model(node_updates)\n",
    "            return node_updates, edge_updates, outputs\n",
    "        return node_updates, edge_updates, None\n",
    "    \n",
    "    # Outputs: (N_train, o) tensor\n",
    "    # Targets: (N_train,) tensor of the classes\n",
    "    def backward(self, outputs, targets):\n",
    "        num_train = range_train[1] - range_train[0]\n",
    "        assert outputs.shape == (num_train, o)\n",
    "        assert targets.shape == (num_train,)\n",
    "        loss = self.loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        # Graph gradient flow\n",
    "        self.graph_grads()\n",
    "        \n",
    "        # Print grad\n",
    "#         for n, p in self.input_model.named_parameters():\n",
    "#             print(p.abs().mean())\n",
    "        \n",
    "        return loss.data.tolist()\n",
    "    \n",
    "    # Given model get grads\n",
    "    def get_layer_grads(self, model):\n",
    "        layers, avg_grads, max_grads = [], [], []\n",
    "        for n, p in model.named_parameters():\n",
    "            if(p.requires_grad) and (\"bias\" not in n):\n",
    "                layers.append(n)\n",
    "                avg_grads.append(p.grad.abs().mean())\n",
    "                max_grads.append(p.grad.abs().max())\n",
    "        return layers, avg_grads, max_grads\n",
    "    \n",
    "    def graph_grads(self):\n",
    "        layers = []\n",
    "        avg_grads = []\n",
    "        max_grads = []\n",
    "        \n",
    "        for model in [self.input_model, self.message_model, self.update_model, self.output_model]:\n",
    "            l, a, m = self.get_layer_grads(model)\n",
    "            layers.extend(l)\n",
    "            avg_grads.extend(a)\n",
    "            max_grads.extend(m)\n",
    "        \n",
    "        plot_grad_flow(layers, avg_grads, max_grads)\n",
    "        \n",
    "    # Just gets the loss for a set (doesnt optimize)\n",
    "    def get_loss(self, outputs, targets):\n",
    "        assert outputs.shape[0] == targets.shape[0]\n",
    "        loss = self.loss(outputs, targets)\n",
    "        return loss.data.tolist()\n",
    "    \n",
    "    def get_accuracy(self, outputs, targets):\n",
    "        assert outputs.shape[0] == targets.shape[0]\n",
    "        outputs_ = np.array(outputs.data.tolist())\n",
    "        output_preds = np.argmax(outputs_, axis=1)\n",
    "        targets = np.array(targets.data.tolist())\n",
    "        acc = ((output_preds == targets).sum()) / targets.shape[0]\n",
    "        return acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
